{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeo22YYl/KOjh7Kyrypquj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrishtinigam/dyslexic-character-recognition/blob/main/PCA_and_K_Fold_Cross_Val_Char_Recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bduJ6YKLU-2s"
      },
      "source": [
        "# Building the dataset\n",
        "### Getting the images from the drive folder\n",
        "\n",
        "(Normal, Reversed) Larger CNN 1000 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEY8R22hmA7H",
        "outputId": "b62bde0e-5542-44ea-918d-610759d526d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kYJqzIRkUy4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek4KuEzWoPrz"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1X8erXDjmU0"
      },
      "source": [
        "## TARGET: Given a single image of a letter, the model is able to classify it as \"Normal\" or \"Dyslexic\" and able to tell character it is, as well as what it is supposed to be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kGiuOU-m4hB"
      },
      "outputs": [],
      "source": [
        "alphabets = []\n",
        "for letter in string.ascii_uppercase:\n",
        "  alphabets.append(letter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pU2NvSQnysk"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "x = 0\n",
        "for letter in alphabets:\n",
        "  image_paths = glob.glob(f\"/content/drive/My Drive/TrainNormal20/\" + letter + \"*.png\")\n",
        "  for i in image_paths:\n",
        "    image = cv2.imread(i)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    images.append([image, x])\n",
        "  x += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"for letter in alphabets:\n",
        "  image_paths_dyx = glob.glob(f\"/content/drive/My Drive/TrainDyslexic20/\" + letter + \"*.png\")\n",
        "  for i in image_paths_dyx:\n",
        "    image = cv2.imread(i)\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    images.append([image, x])\n",
        "  x += 1\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "iP2uAPtfZCMA",
        "outputId": "0370869c-86db-4c26-f0ed-600369db8531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for letter in alphabets:\\n  image_paths_dyx = glob.glob(f\"/content/drive/My Drive/TrainDyslexic20/\" + letter + \"*.png\")\\n  for i in image_paths_dyx:\\n    image = cv2.imread(i)\\n    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n    images.append([image, x])\\n  x += 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12RcCSINCmqE"
      },
      "outputs": [],
      "source": [
        "x = 26\n",
        "image_paths_dyx = glob.glob(f\"/content/drive/My Drive/TrainDyslexic20/*.png\")\n",
        "for i in image_paths_dyx:\n",
        "  image = cv2.imread(i)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  images.append([image, x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo3DywB9w-ey"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seaDU1v1xDEX"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu0VLLQr2asn",
        "outputId": "071bc635-c883-4289-999e-4a45f450a9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1042 entries, 0 to 1041\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       1042 non-null   object\n",
            " 1   1       1042 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 16.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYPfZrQY2g5o",
        "outputId": "d3755dff-3c64-4ecf-84ad-f91c2d5401fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1042, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7ZNCo91hA47s",
        "outputId": "2953a39d-f8be-4bf8-8f51-7a42b105f42b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0   1\n",
              "0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   0\n",
              "1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   0\n",
              "2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   0\n",
              "3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   0\n",
              "4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   0\n",
              "...                                                 ...  ..\n",
              "1037  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  26\n",
              "1038  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  26\n",
              "1039  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  26\n",
              "1040  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  26\n",
              "1041  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  26\n",
              "\n",
              "[1042 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a6489134-6977-4cfb-921f-35dcf7ab3038\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1040</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041</th>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1042 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6489134-6977-4cfb-921f-35dcf7ab3038')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-9d8f485d-3d9e-4cfc-aea2-9ce46e5e8b9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d8f485d-3d9e-4cfc-aea2-9ce46e5e8b9c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-9d8f485d-3d9e-4cfc-aea2-9ce46e5e8b9c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6489134-6977-4cfb-921f-35dcf7ab3038 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6489134-6977-4cfb-921f-35dcf7ab3038');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwWOrYxPAxiM"
      },
      "outputs": [],
      "source": [
        "df.rename(columns = {0:'Character', 1:'Class'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFTOyW3hA5Bw",
        "outputId": "16601b3a-0cdf-49e2-86fd-231947eda96f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Character', 'Class'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7uM1_xzBJgJ"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeqb1rTuHlW3"
      },
      "outputs": [],
      "source": [
        "def zeroPadTill(image, r, c):\n",
        "  ri, ci = image.shape\n",
        "  # ri, ci, x = image.shape\n",
        "  pad_rows = r-ri\n",
        "  pad_cols = c-ci\n",
        "  image = cv2.copyMakeBorder(image, pad_rows, 0, pad_cols, 0, cv2.BORDER_CONSTANT)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26p_6se7HZ88"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for image in df['Character']:\n",
        "  image = zeroPadTill(image, 32, 32)\n",
        "  image = image.flatten()\n",
        "  data.append(image)\n",
        "data = np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(data.shape[0]):\n",
        "  #print(data[i].shape)\n",
        "  if(data[i].shape[0] != 32 or data[i].shape[1] != 32):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "3G9rJXmQnUQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ade9e9-0b5c-4bd6-adf5-8e59fc1ff5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['Class'].to_numpy()"
      ],
      "metadata": {
        "id": "LqpQUGXynjT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f7Gp4_YiZW5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten , Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vgeULZdDZXKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(data)\n",
        "labels = pd.DataFrame(labels)"
      ],
      "metadata": {
        "id": "L0aK3pWjvzqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the larger model\n",
        "def larger_model(input_shape):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(30, (5, 5), input_shape=input_shape, activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(50, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "WrwSpn-KnK1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(x_train, x_test, y_train,  y_test, y_test_df, input_shape, fold):\n",
        "  print(\"FOLD NO: \", fold)\n",
        "  # build the model\n",
        "  print(\"input shape\", input_shape)\n",
        "  model = larger_model(input_shape)\n",
        "  # Fit the model\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=200)\n",
        "  # Final evaluation of the model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "  predicts = model.predict(x_test)\n",
        "\n",
        "  predicts_labels = []\n",
        "  for i in predicts:\n",
        "    predicts_labels.append(np.argmax(i))\n",
        "  predicts_labels = np.array(predicts_labels)\n",
        "\n",
        "\n",
        "\n",
        "  y_test_df = np.array(y_test_df)\n",
        "\n",
        "  from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score\n",
        "  print('Precision: %.3f' % precision_score(y_test_df,predicts_labels,average='micro'))\n",
        "  print('Recall: %.3f' % recall_score(y_test_df, predicts_labels,average='micro'))\n",
        "  print('Accuracy: %.3f' % accuracy_score(y_test_df, predicts_labels))\n",
        "  print('F1-Score: %.3f' % f1_score(y_test_df, predicts_labels,average='micro'))\n",
        "\n",
        "  return accuracy_score(y_test_df, predicts_labels)"
      ],
      "metadata": {
        "id": "ApCB9ErLrbS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def closestDivisors(n):\n",
        "    a = round(math.sqrt(n))\n",
        "    while n%a > 0: a -= 1\n",
        "    return a,n//a"
      ],
      "metadata": {
        "id": "bu-5pCgkdTiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = KFold(n_splits = 10, random_state = 7, shuffle = True)\n",
        "fold = 1\n",
        "scores = []\n",
        "for train_index, val_index in skf.split(np.zeros(len(data)), labels):\n",
        "  training_data = data.iloc[train_index]\n",
        "  training_labels = labels.iloc[train_index]\n",
        "  validation_data = data.iloc[val_index]\n",
        "  validation_labels = labels.iloc[val_index]\n",
        "\n",
        "\n",
        "\n",
        "  np_training_data = training_data.to_numpy()\n",
        "  #np_training_data = np.reshape(np_training_data, (np_training_data.shape[0], 32, 32))\n",
        "\n",
        "  np_validation_data = validation_data.to_numpy()\n",
        "  #np_validation_data = np.reshape(np_validation_data, (np_validation_data.shape[0], 32, 32))\n",
        "\n",
        "  np_training_labels = training_labels.to_numpy()\n",
        "  np_validation_labels = validation_labels.to_numpy()\n",
        "\n",
        "  data_np = np.vstack((np_training_data, np_validation_data))\n",
        "  labels_np = np.vstack((np_training_labels, np_validation_labels))\n",
        "\n",
        "  pca = PCA(0.942)\n",
        "  data_np_pca = pca.fit_transform(data_np)\n",
        "  print(pca.explained_variance_ratio_)\n",
        "  print(pca.n_components_)\n",
        "\n",
        "  r, c = closestDivisors(pca.n_components_)\n",
        "  print(r,c)\n",
        "  if(r < 6 or c < 6):\n",
        "    continue\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(data_np_pca, labels_np, test_size=0.3,random_state =42)\n",
        "\n",
        "  x_train = x_train.reshape((x_train.shape[0], r, c, 1)).astype('float32')\n",
        "  x_test = x_test.reshape((x_test.shape[0], r, c, 1)).astype('float32')\n",
        "\n",
        "  x_train = np.array(x_train) / 255\n",
        "  x_test = np.array(x_test) / 255\n",
        "\n",
        "  img_size = 32\n",
        "\n",
        "  y_test_df = y_test.copy()\n",
        "\n",
        "  y_train = np.array(y_train)\n",
        "  y_test = np.array(y_test)\n",
        "\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "\n",
        "  num_classes = df[\"Class\"].unique().size\n",
        "\n",
        "\n",
        "\n",
        "  # X_pca.shape\n",
        "\n",
        "  scores.append(training(x_train, x_test, y_train,  y_test, y_test_df, (r,c,1), fold))\n",
        "  fold += 1"
      ],
      "metadata": {
        "id": "j9Txjhqlrf6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6009d49b-5bcf-48cb-d26d-91d394a06b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  1\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 113ms/step - loss: 3.2651 - accuracy: 0.1043 - val_loss: 3.1798 - val_accuracy: 0.4792\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 3.1073 - accuracy: 0.4952 - val_loss: 3.0090 - val_accuracy: 0.4824\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.8870 - accuracy: 0.5089 - val_loss: 2.7703 - val_accuracy: 0.4824\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.6078 - accuracy: 0.5089 - val_loss: 2.4991 - val_accuracy: 0.4824\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.3312 - accuracy: 0.5089 - val_loss: 2.4004 - val_accuracy: 0.4824\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.3398 - accuracy: 0.5089 - val_loss: 2.4372 - val_accuracy: 0.4824\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.3164 - accuracy: 0.5089 - val_loss: 2.3473 - val_accuracy: 0.4824\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.2270 - accuracy: 0.5089 - val_loss: 2.3296 - val_accuracy: 0.4824\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.2249 - accuracy: 0.5089 - val_loss: 2.3384 - val_accuracy: 0.4824\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2255 - accuracy: 0.5089 - val_loss: 2.3124 - val_accuracy: 0.4824\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.1832 - accuracy: 0.5089 - val_loss: 2.2831 - val_accuracy: 0.4824\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.1828 - accuracy: 0.5089 - val_loss: 2.2741 - val_accuracy: 0.4824\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.1617 - accuracy: 0.5089 - val_loss: 2.2667 - val_accuracy: 0.4824\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1487 - accuracy: 0.5089 - val_loss: 2.2689 - val_accuracy: 0.4824\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1496 - accuracy: 0.5089 - val_loss: 2.2706 - val_accuracy: 0.4824\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.1347 - accuracy: 0.5089 - val_loss: 2.2557 - val_accuracy: 0.4824\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.1282 - accuracy: 0.5089 - val_loss: 2.2445 - val_accuracy: 0.4824\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.1215 - accuracy: 0.5089 - val_loss: 2.2401 - val_accuracy: 0.4824\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1059 - accuracy: 0.5089 - val_loss: 2.2396 - val_accuracy: 0.4824\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.1095 - accuracy: 0.5089 - val_loss: 2.2417 - val_accuracy: 0.4824\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.1003 - accuracy: 0.5089 - val_loss: 2.2322 - val_accuracy: 0.4824\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.0830 - accuracy: 0.5089 - val_loss: 2.2186 - val_accuracy: 0.4824\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0850 - accuracy: 0.5089 - val_loss: 2.2143 - val_accuracy: 0.4824\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0703 - accuracy: 0.5089 - val_loss: 2.2164 - val_accuracy: 0.4824\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.0604 - accuracy: 0.5089 - val_loss: 2.2192 - val_accuracy: 0.4824\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.0564 - accuracy: 0.5089 - val_loss: 2.2109 - val_accuracy: 0.4824\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.0428 - accuracy: 0.5089 - val_loss: 2.1980 - val_accuracy: 0.4824\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0317 - accuracy: 0.5089 - val_loss: 2.1901 - val_accuracy: 0.4824\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0379 - accuracy: 0.5089 - val_loss: 2.1903 - val_accuracy: 0.4824\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.0210 - accuracy: 0.5089 - val_loss: 2.1841 - val_accuracy: 0.4824\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.0138 - accuracy: 0.5089 - val_loss: 2.1813 - val_accuracy: 0.4824\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0113 - accuracy: 0.5089 - val_loss: 2.1677 - val_accuracy: 0.4824\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0014 - accuracy: 0.5089 - val_loss: 2.1624 - val_accuracy: 0.4824\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.9842 - accuracy: 0.5089 - val_loss: 2.1594 - val_accuracy: 0.4824\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9820 - accuracy: 0.5089 - val_loss: 2.1525 - val_accuracy: 0.4824\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9740 - accuracy: 0.5089 - val_loss: 2.1508 - val_accuracy: 0.4824\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9632 - accuracy: 0.5089 - val_loss: 2.1323 - val_accuracy: 0.4824\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9468 - accuracy: 0.5089 - val_loss: 2.1257 - val_accuracy: 0.4824\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.9381 - accuracy: 0.5089 - val_loss: 2.1318 - val_accuracy: 0.4824\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9265 - accuracy: 0.5089 - val_loss: 2.1096 - val_accuracy: 0.4824\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9225 - accuracy: 0.5089 - val_loss: 2.1038 - val_accuracy: 0.4824\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8972 - accuracy: 0.5089 - val_loss: 2.0997 - val_accuracy: 0.4824\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8948 - accuracy: 0.5089 - val_loss: 2.0855 - val_accuracy: 0.4824\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.8796 - accuracy: 0.5089 - val_loss: 2.0774 - val_accuracy: 0.4824\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.8697 - accuracy: 0.5089 - val_loss: 2.0699 - val_accuracy: 0.4824\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8671 - accuracy: 0.5089 - val_loss: 2.0660 - val_accuracy: 0.4824\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8334 - accuracy: 0.5089 - val_loss: 2.0551 - val_accuracy: 0.4824\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8392 - accuracy: 0.5089 - val_loss: 2.0479 - val_accuracy: 0.4824\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8046 - accuracy: 0.5089 - val_loss: 2.0394 - val_accuracy: 0.4824\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.8065 - accuracy: 0.5089 - val_loss: 2.0353 - val_accuracy: 0.4824\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.7879 - accuracy: 0.5089 - val_loss: 2.0286 - val_accuracy: 0.4824\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.7723 - accuracy: 0.5089 - val_loss: 2.0235 - val_accuracy: 0.4824\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.7577 - accuracy: 0.5089 - val_loss: 2.0233 - val_accuracy: 0.4824\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.7407 - accuracy: 0.5089 - val_loss: 2.0147 - val_accuracy: 0.4824\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.7206 - accuracy: 0.5089 - val_loss: 2.0179 - val_accuracy: 0.4824\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.7228 - accuracy: 0.5103 - val_loss: 2.0117 - val_accuracy: 0.4824\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.7071 - accuracy: 0.5117 - val_loss: 2.0075 - val_accuracy: 0.4824\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.6958 - accuracy: 0.5130 - val_loss: 2.0015 - val_accuracy: 0.4792\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 1.6930 - accuracy: 0.5144 - val_loss: 2.0129 - val_accuracy: 0.4792\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 1.6828 - accuracy: 0.5158 - val_loss: 1.9986 - val_accuracy: 0.4760\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 1.6640 - accuracy: 0.5158 - val_loss: 2.0189 - val_accuracy: 0.4792\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6584 - accuracy: 0.5144 - val_loss: 1.9974 - val_accuracy: 0.4824\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.6524 - accuracy: 0.5185 - val_loss: 2.0146 - val_accuracy: 0.4792\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.6455 - accuracy: 0.5158 - val_loss: 2.0071 - val_accuracy: 0.4824\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.6302 - accuracy: 0.5199 - val_loss: 2.0081 - val_accuracy: 0.4824\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.6117 - accuracy: 0.5240 - val_loss: 2.0235 - val_accuracy: 0.4856\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.6067 - accuracy: 0.5185 - val_loss: 2.0046 - val_accuracy: 0.4856\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.6056 - accuracy: 0.5213 - val_loss: 2.0122 - val_accuracy: 0.4888\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.5922 - accuracy: 0.5281 - val_loss: 2.0168 - val_accuracy: 0.4952\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.5745 - accuracy: 0.5267 - val_loss: 2.0290 - val_accuracy: 0.4952\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.5681 - accuracy: 0.5295 - val_loss: 1.9851 - val_accuracy: 0.4920\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.5518 - accuracy: 0.5405 - val_loss: 2.0809 - val_accuracy: 0.4952\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.5416 - accuracy: 0.5364 - val_loss: 1.9971 - val_accuracy: 0.5016\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5284 - accuracy: 0.5514 - val_loss: 2.0358 - val_accuracy: 0.5016\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.5076 - accuracy: 0.5487 - val_loss: 1.9773 - val_accuracy: 0.4920\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5010 - accuracy: 0.5528 - val_loss: 2.0622 - val_accuracy: 0.5048\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.4667 - accuracy: 0.5583 - val_loss: 2.0067 - val_accuracy: 0.5112\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.4327 - accuracy: 0.5734 - val_loss: 2.0334 - val_accuracy: 0.5080\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.4363 - accuracy: 0.5816 - val_loss: 2.0287 - val_accuracy: 0.5112\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4047 - accuracy: 0.5789 - val_loss: 1.9990 - val_accuracy: 0.5144\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3846 - accuracy: 0.5898 - val_loss: 2.0406 - val_accuracy: 0.5144\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.3621 - accuracy: 0.5844 - val_loss: 1.9655 - val_accuracy: 0.5176\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.3429 - accuracy: 0.5995 - val_loss: 2.0258 - val_accuracy: 0.5272\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.3209 - accuracy: 0.6091 - val_loss: 1.9818 - val_accuracy: 0.5367\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3188 - accuracy: 0.6077 - val_loss: 2.0149 - val_accuracy: 0.5272\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.2880 - accuracy: 0.6022 - val_loss: 1.9854 - val_accuracy: 0.5240\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.2611 - accuracy: 0.6118 - val_loss: 2.0112 - val_accuracy: 0.5304\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.2267 - accuracy: 0.6392 - val_loss: 1.9929 - val_accuracy: 0.5495\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.2222 - accuracy: 0.6241 - val_loss: 1.9971 - val_accuracy: 0.5431\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.1807 - accuracy: 0.6406 - val_loss: 2.0425 - val_accuracy: 0.5399\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.1604 - accuracy: 0.6406 - val_loss: 2.1132 - val_accuracy: 0.5495\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.1403 - accuracy: 0.6324 - val_loss: 2.0267 - val_accuracy: 0.5367\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.1454 - accuracy: 0.6461 - val_loss: 2.1144 - val_accuracy: 0.5463\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.0948 - accuracy: 0.6722 - val_loss: 2.0670 - val_accuracy: 0.5463\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.1091 - accuracy: 0.6694 - val_loss: 2.1606 - val_accuracy: 0.5431\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.0729 - accuracy: 0.6694 - val_loss: 2.1204 - val_accuracy: 0.5463\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0584 - accuracy: 0.6845 - val_loss: 2.0405 - val_accuracy: 0.5495\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.0272 - accuracy: 0.6955 - val_loss: 2.3020 - val_accuracy: 0.5655\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.0467 - accuracy: 0.6900 - val_loss: 2.0678 - val_accuracy: 0.5527\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0002 - accuracy: 0.6941 - val_loss: 2.2361 - val_accuracy: 0.5655\n",
            "Large CNN Error: 43.45%\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Precision: 0.565\n",
            "Recall: 0.565\n",
            "Accuracy: 0.565\n",
            "F1-Score: 0.565\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  2\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 110ms/step - loss: 3.2591 - accuracy: 0.1303 - val_loss: 3.1761 - val_accuracy: 0.5208\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 3.1343 - accuracy: 0.4870 - val_loss: 3.0058 - val_accuracy: 0.5208\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.9412 - accuracy: 0.4925 - val_loss: 2.7339 - val_accuracy: 0.5208\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.6594 - accuracy: 0.4925 - val_loss: 2.3795 - val_accuracy: 0.5208\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 2.3888 - accuracy: 0.4925 - val_loss: 2.2148 - val_accuracy: 0.5208\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 2.4201 - accuracy: 0.4925 - val_loss: 2.2435 - val_accuracy: 0.5208\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 2.3726 - accuracy: 0.4925 - val_loss: 2.1806 - val_accuracy: 0.5208\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.3025 - accuracy: 0.4925 - val_loss: 2.2144 - val_accuracy: 0.5208\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.3021 - accuracy: 0.4925 - val_loss: 2.2327 - val_accuracy: 0.5208\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.2853 - accuracy: 0.4925 - val_loss: 2.1981 - val_accuracy: 0.5208\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2475 - accuracy: 0.4925 - val_loss: 2.1574 - val_accuracy: 0.5208\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2319 - accuracy: 0.4925 - val_loss: 2.1457 - val_accuracy: 0.5208\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2440 - accuracy: 0.4925 - val_loss: 2.1430 - val_accuracy: 0.5208\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.2278 - accuracy: 0.4925 - val_loss: 2.1517 - val_accuracy: 0.5208\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.2081 - accuracy: 0.4925 - val_loss: 2.1492 - val_accuracy: 0.5208\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.2101 - accuracy: 0.4925 - val_loss: 2.1385 - val_accuracy: 0.5208\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1970 - accuracy: 0.4925 - val_loss: 2.1252 - val_accuracy: 0.5208\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.1944 - accuracy: 0.4925 - val_loss: 2.1176 - val_accuracy: 0.5208\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1730 - accuracy: 0.4925 - val_loss: 2.1218 - val_accuracy: 0.5208\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.1723 - accuracy: 0.4925 - val_loss: 2.1250 - val_accuracy: 0.5208\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1631 - accuracy: 0.4925 - val_loss: 2.1163 - val_accuracy: 0.5208\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1594 - accuracy: 0.4925 - val_loss: 2.0996 - val_accuracy: 0.5208\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1499 - accuracy: 0.4925 - val_loss: 2.0921 - val_accuracy: 0.5208\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1323 - accuracy: 0.4925 - val_loss: 2.0922 - val_accuracy: 0.5208\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.1355 - accuracy: 0.4925 - val_loss: 2.0969 - val_accuracy: 0.5208\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.1215 - accuracy: 0.4925 - val_loss: 2.0798 - val_accuracy: 0.5208\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 2.1058 - accuracy: 0.4925 - val_loss: 2.0661 - val_accuracy: 0.5208\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.0993 - accuracy: 0.4925 - val_loss: 2.0761 - val_accuracy: 0.5208\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.1002 - accuracy: 0.4925 - val_loss: 2.0780 - val_accuracy: 0.5208\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.0953 - accuracy: 0.4925 - val_loss: 2.0673 - val_accuracy: 0.5208\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.0825 - accuracy: 0.4925 - val_loss: 2.0544 - val_accuracy: 0.5208\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0853 - accuracy: 0.4925 - val_loss: 2.0447 - val_accuracy: 0.5208\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.0560 - accuracy: 0.4925 - val_loss: 2.0484 - val_accuracy: 0.5208\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.0523 - accuracy: 0.4925 - val_loss: 2.0485 - val_accuracy: 0.5208\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0422 - accuracy: 0.4925 - val_loss: 2.0338 - val_accuracy: 0.5208\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.0319 - accuracy: 0.4925 - val_loss: 2.0202 - val_accuracy: 0.5208\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.0303 - accuracy: 0.4925 - val_loss: 2.0247 - val_accuracy: 0.5208\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.0291 - accuracy: 0.4925 - val_loss: 2.0246 - val_accuracy: 0.5208\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.0089 - accuracy: 0.4925 - val_loss: 2.0157 - val_accuracy: 0.5208\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.9931 - accuracy: 0.4925 - val_loss: 2.0060 - val_accuracy: 0.5208\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.9882 - accuracy: 0.4925 - val_loss: 2.0044 - val_accuracy: 0.5208\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.9770 - accuracy: 0.4925 - val_loss: 1.9882 - val_accuracy: 0.5208\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.9579 - accuracy: 0.4925 - val_loss: 1.9873 - val_accuracy: 0.5208\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.9510 - accuracy: 0.4925 - val_loss: 1.9955 - val_accuracy: 0.5208\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.9455 - accuracy: 0.4925 - val_loss: 1.9701 - val_accuracy: 0.5208\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.9205 - accuracy: 0.4925 - val_loss: 1.9679 - val_accuracy: 0.5208\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.9074 - accuracy: 0.4925 - val_loss: 1.9687 - val_accuracy: 0.5208\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.8983 - accuracy: 0.4925 - val_loss: 1.9553 - val_accuracy: 0.5208\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.8863 - accuracy: 0.4925 - val_loss: 1.9543 - val_accuracy: 0.5208\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.8761 - accuracy: 0.4925 - val_loss: 1.9585 - val_accuracy: 0.5208\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.8657 - accuracy: 0.4925 - val_loss: 1.9434 - val_accuracy: 0.5208\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.8440 - accuracy: 0.4925 - val_loss: 1.9465 - val_accuracy: 0.5208\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8357 - accuracy: 0.4925 - val_loss: 1.9453 - val_accuracy: 0.5208\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.8197 - accuracy: 0.4925 - val_loss: 1.9476 - val_accuracy: 0.5208\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.8143 - accuracy: 0.4925 - val_loss: 1.9483 - val_accuracy: 0.5208\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.8022 - accuracy: 0.4925 - val_loss: 1.9484 - val_accuracy: 0.5208\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7986 - accuracy: 0.4952 - val_loss: 1.9504 - val_accuracy: 0.5208\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7656 - accuracy: 0.4938 - val_loss: 1.9620 - val_accuracy: 0.5208\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7677 - accuracy: 0.4925 - val_loss: 1.9633 - val_accuracy: 0.5208\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.7616 - accuracy: 0.4925 - val_loss: 1.9654 - val_accuracy: 0.5208\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.7438 - accuracy: 0.4952 - val_loss: 1.9691 - val_accuracy: 0.5240\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.7395 - accuracy: 0.4911 - val_loss: 1.9738 - val_accuracy: 0.5272\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.7288 - accuracy: 0.4952 - val_loss: 1.9789 - val_accuracy: 0.5272\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7113 - accuracy: 0.5034 - val_loss: 1.9831 - val_accuracy: 0.5272\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.7084 - accuracy: 0.5048 - val_loss: 1.9778 - val_accuracy: 0.5272\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7017 - accuracy: 0.5048 - val_loss: 1.9980 - val_accuracy: 0.5272\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.6918 - accuracy: 0.5021 - val_loss: 1.9845 - val_accuracy: 0.5272\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.6769 - accuracy: 0.5021 - val_loss: 1.9908 - val_accuracy: 0.5272\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.6682 - accuracy: 0.5062 - val_loss: 2.0024 - val_accuracy: 0.5240\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.6623 - accuracy: 0.5089 - val_loss: 2.0035 - val_accuracy: 0.5240\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.6439 - accuracy: 0.5089 - val_loss: 2.0134 - val_accuracy: 0.5240\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.6272 - accuracy: 0.5089 - val_loss: 2.0009 - val_accuracy: 0.5176\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.6237 - accuracy: 0.5048 - val_loss: 2.0349 - val_accuracy: 0.5240\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.6161 - accuracy: 0.5075 - val_loss: 2.0105 - val_accuracy: 0.5208\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6005 - accuracy: 0.5130 - val_loss: 2.0358 - val_accuracy: 0.5208\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5920 - accuracy: 0.5130 - val_loss: 2.0151 - val_accuracy: 0.5208\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.5738 - accuracy: 0.5144 - val_loss: 2.0521 - val_accuracy: 0.5240\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.5639 - accuracy: 0.5199 - val_loss: 2.0337 - val_accuracy: 0.5240\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.5428 - accuracy: 0.5185 - val_loss: 2.0569 - val_accuracy: 0.5240\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5346 - accuracy: 0.5213 - val_loss: 2.0754 - val_accuracy: 0.5240\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5020 - accuracy: 0.5336 - val_loss: 2.0519 - val_accuracy: 0.5304\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5024 - accuracy: 0.5405 - val_loss: 2.0914 - val_accuracy: 0.5304\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.4736 - accuracy: 0.5514 - val_loss: 2.0497 - val_accuracy: 0.5431\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4562 - accuracy: 0.5460 - val_loss: 2.0895 - val_accuracy: 0.5399\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.4386 - accuracy: 0.5652 - val_loss: 2.0735 - val_accuracy: 0.5527\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.3886 - accuracy: 0.5706 - val_loss: 2.1096 - val_accuracy: 0.5527\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.4054 - accuracy: 0.5775 - val_loss: 2.0777 - val_accuracy: 0.5431\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3626 - accuracy: 0.5967 - val_loss: 2.1204 - val_accuracy: 0.5623\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3238 - accuracy: 0.5940 - val_loss: 2.1036 - val_accuracy: 0.5527\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3491 - accuracy: 0.6077 - val_loss: 2.1138 - val_accuracy: 0.5527\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.2934 - accuracy: 0.6132 - val_loss: 2.1148 - val_accuracy: 0.5655\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.2682 - accuracy: 0.6241 - val_loss: 2.1192 - val_accuracy: 0.5623\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.2573 - accuracy: 0.6433 - val_loss: 2.1794 - val_accuracy: 0.5719\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.2259 - accuracy: 0.6571 - val_loss: 2.2699 - val_accuracy: 0.5687\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.2316 - accuracy: 0.6365 - val_loss: 2.1544 - val_accuracy: 0.5431\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1997 - accuracy: 0.6475 - val_loss: 2.1788 - val_accuracy: 0.5623\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1623 - accuracy: 0.6639 - val_loss: 2.2405 - val_accuracy: 0.5815\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.1227 - accuracy: 0.6680 - val_loss: 2.1860 - val_accuracy: 0.5591\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1636 - accuracy: 0.6475 - val_loss: 2.3148 - val_accuracy: 0.5751\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.0980 - accuracy: 0.6818 - val_loss: 2.2582 - val_accuracy: 0.5687\n",
            "Large CNN Error: 43.13%\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "Precision: 0.569\n",
            "Recall: 0.569\n",
            "Accuracy: 0.569\n",
            "F1-Score: 0.569\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  3\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 92ms/step - loss: 3.2456 - accuracy: 0.0219 - val_loss: 3.1699 - val_accuracy: 0.0160\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.0863 - accuracy: 0.2085 - val_loss: 2.9825 - val_accuracy: 0.4952\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.8485 - accuracy: 0.5021 - val_loss: 2.7085 - val_accuracy: 0.4952\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.5390 - accuracy: 0.5034 - val_loss: 2.4479 - val_accuracy: 0.4952\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.3764 - accuracy: 0.5034 - val_loss: 2.4265 - val_accuracy: 0.4952\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.4198 - accuracy: 0.5034 - val_loss: 2.3866 - val_accuracy: 0.4952\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.3252 - accuracy: 0.5034 - val_loss: 2.3266 - val_accuracy: 0.4952\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.2611 - accuracy: 0.5034 - val_loss: 2.3431 - val_accuracy: 0.4952\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.2662 - accuracy: 0.5034 - val_loss: 2.3260 - val_accuracy: 0.4952\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.2282 - accuracy: 0.5034 - val_loss: 2.2805 - val_accuracy: 0.4952\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2081 - accuracy: 0.5034 - val_loss: 2.2585 - val_accuracy: 0.4952\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.2028 - accuracy: 0.5034 - val_loss: 2.2456 - val_accuracy: 0.4952\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1790 - accuracy: 0.5034 - val_loss: 2.2422 - val_accuracy: 0.4952\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1666 - accuracy: 0.5034 - val_loss: 2.2397 - val_accuracy: 0.4952\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.1531 - accuracy: 0.5034 - val_loss: 2.2176 - val_accuracy: 0.4952\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.1430 - accuracy: 0.5034 - val_loss: 2.1989 - val_accuracy: 0.4952\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1365 - accuracy: 0.5034 - val_loss: 2.1916 - val_accuracy: 0.4952\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.1017 - accuracy: 0.5034 - val_loss: 2.1902 - val_accuracy: 0.4952\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1135 - accuracy: 0.5034 - val_loss: 2.1886 - val_accuracy: 0.4952\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.1038 - accuracy: 0.5034 - val_loss: 2.1716 - val_accuracy: 0.4952\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0919 - accuracy: 0.5034 - val_loss: 2.1615 - val_accuracy: 0.4952\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.0733 - accuracy: 0.5034 - val_loss: 2.1601 - val_accuracy: 0.4952\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0709 - accuracy: 0.5034 - val_loss: 2.1576 - val_accuracy: 0.4952\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0464 - accuracy: 0.5034 - val_loss: 2.1493 - val_accuracy: 0.4952\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0526 - accuracy: 0.5034 - val_loss: 2.1401 - val_accuracy: 0.4952\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.0479 - accuracy: 0.5034 - val_loss: 2.1356 - val_accuracy: 0.4952\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.0298 - accuracy: 0.5034 - val_loss: 2.1296 - val_accuracy: 0.4952\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0311 - accuracy: 0.5034 - val_loss: 2.1305 - val_accuracy: 0.4952\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.0010 - accuracy: 0.5034 - val_loss: 2.1171 - val_accuracy: 0.4952\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.9918 - accuracy: 0.5034 - val_loss: 2.1088 - val_accuracy: 0.4952\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9981 - accuracy: 0.5034 - val_loss: 2.1143 - val_accuracy: 0.4952\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.9789 - accuracy: 0.5034 - val_loss: 2.1036 - val_accuracy: 0.4952\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9687 - accuracy: 0.5034 - val_loss: 2.0942 - val_accuracy: 0.4952\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.9528 - accuracy: 0.5034 - val_loss: 2.0940 - val_accuracy: 0.4952\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9432 - accuracy: 0.5034 - val_loss: 2.0863 - val_accuracy: 0.4952\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.9274 - accuracy: 0.5034 - val_loss: 2.0797 - val_accuracy: 0.4952\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.9308 - accuracy: 0.5034 - val_loss: 2.0763 - val_accuracy: 0.4952\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.9120 - accuracy: 0.5034 - val_loss: 2.0722 - val_accuracy: 0.4952\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8961 - accuracy: 0.5034 - val_loss: 2.0654 - val_accuracy: 0.4952\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.8729 - accuracy: 0.5034 - val_loss: 2.0658 - val_accuracy: 0.4952\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8744 - accuracy: 0.5034 - val_loss: 2.0590 - val_accuracy: 0.4952\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8639 - accuracy: 0.5034 - val_loss: 2.0569 - val_accuracy: 0.4952\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.8579 - accuracy: 0.5034 - val_loss: 2.0494 - val_accuracy: 0.4952\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.8175 - accuracy: 0.5034 - val_loss: 2.0499 - val_accuracy: 0.4952\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.8235 - accuracy: 0.5034 - val_loss: 2.0487 - val_accuracy: 0.4952\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.8049 - accuracy: 0.5034 - val_loss: 2.0539 - val_accuracy: 0.4952\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.8037 - accuracy: 0.5034 - val_loss: 2.0561 - val_accuracy: 0.4952\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7926 - accuracy: 0.5034 - val_loss: 2.0542 - val_accuracy: 0.4952\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.7650 - accuracy: 0.5034 - val_loss: 2.0552 - val_accuracy: 0.4952\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7673 - accuracy: 0.5048 - val_loss: 2.0607 - val_accuracy: 0.4952\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7382 - accuracy: 0.5062 - val_loss: 2.0645 - val_accuracy: 0.4952\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7376 - accuracy: 0.5075 - val_loss: 2.0715 - val_accuracy: 0.4952\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.7332 - accuracy: 0.5048 - val_loss: 2.0734 - val_accuracy: 0.4984\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7177 - accuracy: 0.5075 - val_loss: 2.0866 - val_accuracy: 0.4984\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6925 - accuracy: 0.5117 - val_loss: 2.0879 - val_accuracy: 0.5048\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.6864 - accuracy: 0.5089 - val_loss: 2.1058 - val_accuracy: 0.5048\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6843 - accuracy: 0.5130 - val_loss: 2.0930 - val_accuracy: 0.5080\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6942 - accuracy: 0.5144 - val_loss: 2.1414 - val_accuracy: 0.5048\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6798 - accuracy: 0.5158 - val_loss: 2.0957 - val_accuracy: 0.5048\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.6717 - accuracy: 0.5130 - val_loss: 2.1326 - val_accuracy: 0.5048\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6636 - accuracy: 0.5185 - val_loss: 2.1133 - val_accuracy: 0.5016\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.6518 - accuracy: 0.5185 - val_loss: 2.1725 - val_accuracy: 0.5016\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6509 - accuracy: 0.5199 - val_loss: 2.1389 - val_accuracy: 0.5016\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.6497 - accuracy: 0.5158 - val_loss: 2.1701 - val_accuracy: 0.5016\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.6458 - accuracy: 0.5158 - val_loss: 2.1623 - val_accuracy: 0.5016\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6242 - accuracy: 0.5213 - val_loss: 2.1745 - val_accuracy: 0.5016\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.6283 - accuracy: 0.5199 - val_loss: 2.1954 - val_accuracy: 0.5016\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.6147 - accuracy: 0.5226 - val_loss: 2.1815 - val_accuracy: 0.5048\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.6076 - accuracy: 0.5226 - val_loss: 2.2093 - val_accuracy: 0.5016\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.5975 - accuracy: 0.5199 - val_loss: 2.1871 - val_accuracy: 0.5048\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.5945 - accuracy: 0.5240 - val_loss: 2.2385 - val_accuracy: 0.5080\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.5790 - accuracy: 0.5267 - val_loss: 2.1911 - val_accuracy: 0.5048\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.5722 - accuracy: 0.5254 - val_loss: 2.1956 - val_accuracy: 0.5016\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.5532 - accuracy: 0.5377 - val_loss: 2.2356 - val_accuracy: 0.4984\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5415 - accuracy: 0.5377 - val_loss: 2.1968 - val_accuracy: 0.4952\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5228 - accuracy: 0.5418 - val_loss: 2.1999 - val_accuracy: 0.4952\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.5139 - accuracy: 0.5473 - val_loss: 2.2804 - val_accuracy: 0.5144\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5018 - accuracy: 0.5405 - val_loss: 2.1714 - val_accuracy: 0.4984\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.4865 - accuracy: 0.5556 - val_loss: 2.2658 - val_accuracy: 0.5208\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.4610 - accuracy: 0.5542 - val_loss: 2.2173 - val_accuracy: 0.5016\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.4486 - accuracy: 0.5775 - val_loss: 2.2159 - val_accuracy: 0.5048\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.4430 - accuracy: 0.5652 - val_loss: 2.2862 - val_accuracy: 0.5112\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.3998 - accuracy: 0.5830 - val_loss: 2.2104 - val_accuracy: 0.5080\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.3768 - accuracy: 0.5830 - val_loss: 2.2686 - val_accuracy: 0.5048\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.3738 - accuracy: 0.5926 - val_loss: 2.2611 - val_accuracy: 0.5048\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.3554 - accuracy: 0.5830 - val_loss: 2.2242 - val_accuracy: 0.5080\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.3481 - accuracy: 0.5789 - val_loss: 2.3578 - val_accuracy: 0.5208\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.3105 - accuracy: 0.6036 - val_loss: 2.2468 - val_accuracy: 0.5112\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 1.2842 - accuracy: 0.5940 - val_loss: 2.2634 - val_accuracy: 0.5144\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.3000 - accuracy: 0.6132 - val_loss: 2.4251 - val_accuracy: 0.5144\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.2759 - accuracy: 0.6008 - val_loss: 2.2688 - val_accuracy: 0.5016\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.2450 - accuracy: 0.6077 - val_loss: 2.2927 - val_accuracy: 0.5144\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.2459 - accuracy: 0.6228 - val_loss: 2.4646 - val_accuracy: 0.5144\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.2250 - accuracy: 0.6310 - val_loss: 2.3026 - val_accuracy: 0.5048\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1907 - accuracy: 0.6173 - val_loss: 2.3433 - val_accuracy: 0.5112\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.1810 - accuracy: 0.6324 - val_loss: 2.4721 - val_accuracy: 0.5176\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.1627 - accuracy: 0.6324 - val_loss: 2.3384 - val_accuracy: 0.5048\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.1634 - accuracy: 0.6516 - val_loss: 2.5108 - val_accuracy: 0.5112\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.1250 - accuracy: 0.6488 - val_loss: 2.3297 - val_accuracy: 0.4952\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.1284 - accuracy: 0.6447 - val_loss: 2.4510 - val_accuracy: 0.5016\n",
            "Large CNN Error: 49.84%\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Precision: 0.502\n",
            "Recall: 0.502\n",
            "Accuracy: 0.502\n",
            "F1-Score: 0.502\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  4\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 98ms/step - loss: 3.2771 - accuracy: 0.0219 - val_loss: 3.2232 - val_accuracy: 0.1725\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.1902 - accuracy: 0.3196 - val_loss: 3.1045 - val_accuracy: 0.5112\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 3.0493 - accuracy: 0.4952 - val_loss: 2.9290 - val_accuracy: 0.5112\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.8627 - accuracy: 0.4966 - val_loss: 2.6930 - val_accuracy: 0.5112\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.6184 - accuracy: 0.4966 - val_loss: 2.4345 - val_accuracy: 0.5112\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.4354 - accuracy: 0.4966 - val_loss: 2.3155 - val_accuracy: 0.5112\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.4085 - accuracy: 0.4966 - val_loss: 2.3012 - val_accuracy: 0.5112\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.3823 - accuracy: 0.4966 - val_loss: 2.2389 - val_accuracy: 0.5112\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.3060 - accuracy: 0.4966 - val_loss: 2.2431 - val_accuracy: 0.5112\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.2870 - accuracy: 0.4966 - val_loss: 2.2548 - val_accuracy: 0.5112\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.2708 - accuracy: 0.4966 - val_loss: 2.2203 - val_accuracy: 0.5112\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.2490 - accuracy: 0.4966 - val_loss: 2.1887 - val_accuracy: 0.5112\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.2253 - accuracy: 0.4966 - val_loss: 2.1769 - val_accuracy: 0.5112\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.2075 - accuracy: 0.4966 - val_loss: 2.1766 - val_accuracy: 0.5112\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.2051 - accuracy: 0.4966 - val_loss: 2.1832 - val_accuracy: 0.5112\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.2037 - accuracy: 0.4966 - val_loss: 2.1862 - val_accuracy: 0.5112\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1780 - accuracy: 0.4966 - val_loss: 2.1736 - val_accuracy: 0.5112\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.1837 - accuracy: 0.4966 - val_loss: 2.1599 - val_accuracy: 0.5112\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1753 - accuracy: 0.4966 - val_loss: 2.1536 - val_accuracy: 0.5112\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.1532 - accuracy: 0.4966 - val_loss: 2.1608 - val_accuracy: 0.5112\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1520 - accuracy: 0.4966 - val_loss: 2.1630 - val_accuracy: 0.5112\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1573 - accuracy: 0.4966 - val_loss: 2.1502 - val_accuracy: 0.5112\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1318 - accuracy: 0.4966 - val_loss: 2.1403 - val_accuracy: 0.5112\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1264 - accuracy: 0.4966 - val_loss: 2.1344 - val_accuracy: 0.5112\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.1219 - accuracy: 0.4966 - val_loss: 2.1354 - val_accuracy: 0.5112\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.1211 - accuracy: 0.4966 - val_loss: 2.1383 - val_accuracy: 0.5112\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.1129 - accuracy: 0.4966 - val_loss: 2.1343 - val_accuracy: 0.5112\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1071 - accuracy: 0.4966 - val_loss: 2.1228 - val_accuracy: 0.5112\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.1056 - accuracy: 0.4966 - val_loss: 2.1197 - val_accuracy: 0.5112\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.0930 - accuracy: 0.4966 - val_loss: 2.1216 - val_accuracy: 0.5112\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0921 - accuracy: 0.4966 - val_loss: 2.1216 - val_accuracy: 0.5112\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.0740 - accuracy: 0.4966 - val_loss: 2.1022 - val_accuracy: 0.5112\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0674 - accuracy: 0.4966 - val_loss: 2.1023 - val_accuracy: 0.5112\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0584 - accuracy: 0.4966 - val_loss: 2.0947 - val_accuracy: 0.5112\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.0636 - accuracy: 0.4966 - val_loss: 2.0963 - val_accuracy: 0.5112\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0503 - accuracy: 0.4966 - val_loss: 2.0880 - val_accuracy: 0.5112\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0336 - accuracy: 0.4966 - val_loss: 2.0773 - val_accuracy: 0.5112\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0371 - accuracy: 0.4966 - val_loss: 2.0770 - val_accuracy: 0.5112\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0161 - accuracy: 0.4966 - val_loss: 2.0774 - val_accuracy: 0.5112\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0099 - accuracy: 0.4966 - val_loss: 2.0519 - val_accuracy: 0.5112\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0009 - accuracy: 0.4966 - val_loss: 2.0466 - val_accuracy: 0.5112\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.9806 - accuracy: 0.4966 - val_loss: 2.0547 - val_accuracy: 0.5112\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9912 - accuracy: 0.4966 - val_loss: 2.0346 - val_accuracy: 0.5112\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9580 - accuracy: 0.4966 - val_loss: 2.0220 - val_accuracy: 0.5112\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9572 - accuracy: 0.4966 - val_loss: 2.0251 - val_accuracy: 0.5112\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.9409 - accuracy: 0.4966 - val_loss: 2.0027 - val_accuracy: 0.5112\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.9213 - accuracy: 0.4966 - val_loss: 1.9944 - val_accuracy: 0.5112\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9066 - accuracy: 0.4966 - val_loss: 1.9911 - val_accuracy: 0.5112\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8958 - accuracy: 0.4966 - val_loss: 1.9785 - val_accuracy: 0.5112\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.8659 - accuracy: 0.4966 - val_loss: 1.9708 - val_accuracy: 0.5112\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.8627 - accuracy: 0.4966 - val_loss: 1.9635 - val_accuracy: 0.5112\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.8536 - accuracy: 0.4966 - val_loss: 1.9556 - val_accuracy: 0.5112\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.8369 - accuracy: 0.4966 - val_loss: 1.9592 - val_accuracy: 0.5112\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.8174 - accuracy: 0.4979 - val_loss: 1.9491 - val_accuracy: 0.5112\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.8116 - accuracy: 0.4993 - val_loss: 1.9511 - val_accuracy: 0.5080\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.7961 - accuracy: 0.5034 - val_loss: 1.9436 - val_accuracy: 0.5080\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.7947 - accuracy: 0.5007 - val_loss: 1.9446 - val_accuracy: 0.5080\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.7852 - accuracy: 0.5034 - val_loss: 1.9397 - val_accuracy: 0.5080\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.7544 - accuracy: 0.5021 - val_loss: 1.9379 - val_accuracy: 0.5080\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.7486 - accuracy: 0.5062 - val_loss: 1.9386 - val_accuracy: 0.5080\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.7233 - accuracy: 0.5062 - val_loss: 1.9357 - val_accuracy: 0.5080\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.7268 - accuracy: 0.5075 - val_loss: 1.9382 - val_accuracy: 0.5080\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.7156 - accuracy: 0.5089 - val_loss: 1.9356 - val_accuracy: 0.5080\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6937 - accuracy: 0.5089 - val_loss: 1.9355 - val_accuracy: 0.5080\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.7026 - accuracy: 0.5089 - val_loss: 1.9379 - val_accuracy: 0.5080\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.6793 - accuracy: 0.5103 - val_loss: 1.9372 - val_accuracy: 0.5048\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.6698 - accuracy: 0.5103 - val_loss: 1.9399 - val_accuracy: 0.5048\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.6569 - accuracy: 0.5103 - val_loss: 1.9393 - val_accuracy: 0.5048\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 1.6485 - accuracy: 0.5130 - val_loss: 1.9334 - val_accuracy: 0.4984\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 145ms/step - loss: 1.6464 - accuracy: 0.5130 - val_loss: 1.9481 - val_accuracy: 0.5016\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 1.6364 - accuracy: 0.5075 - val_loss: 1.9308 - val_accuracy: 0.4984\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.6231 - accuracy: 0.5103 - val_loss: 1.9502 - val_accuracy: 0.4984\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.6072 - accuracy: 0.5144 - val_loss: 1.9318 - val_accuracy: 0.5016\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.6024 - accuracy: 0.5213 - val_loss: 1.9392 - val_accuracy: 0.5016\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5655 - accuracy: 0.5185 - val_loss: 1.9334 - val_accuracy: 0.5016\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5472 - accuracy: 0.5213 - val_loss: 1.9255 - val_accuracy: 0.5048\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5490 - accuracy: 0.5350 - val_loss: 1.9230 - val_accuracy: 0.5016\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.5180 - accuracy: 0.5254 - val_loss: 1.9225 - val_accuracy: 0.5080\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5047 - accuracy: 0.5514 - val_loss: 1.9299 - val_accuracy: 0.5048\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.5132 - accuracy: 0.5405 - val_loss: 1.9085 - val_accuracy: 0.5048\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.4726 - accuracy: 0.5638 - val_loss: 1.9317 - val_accuracy: 0.5080\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.4462 - accuracy: 0.5802 - val_loss: 1.9201 - val_accuracy: 0.5176\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4488 - accuracy: 0.5501 - val_loss: 1.9302 - val_accuracy: 0.5208\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.4160 - accuracy: 0.5734 - val_loss: 1.9337 - val_accuracy: 0.5112\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.4122 - accuracy: 0.5830 - val_loss: 1.9135 - val_accuracy: 0.4920\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3803 - accuracy: 0.6049 - val_loss: 1.9974 - val_accuracy: 0.5176\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.3694 - accuracy: 0.5857 - val_loss: 1.9259 - val_accuracy: 0.4984\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3246 - accuracy: 0.6228 - val_loss: 1.9676 - val_accuracy: 0.5112\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.3124 - accuracy: 0.6132 - val_loss: 1.9554 - val_accuracy: 0.4984\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.2912 - accuracy: 0.6200 - val_loss: 2.0080 - val_accuracy: 0.5112\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.2637 - accuracy: 0.6283 - val_loss: 1.9821 - val_accuracy: 0.5016\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.2703 - accuracy: 0.6324 - val_loss: 1.9704 - val_accuracy: 0.4984\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.2453 - accuracy: 0.6269 - val_loss: 2.0047 - val_accuracy: 0.5048\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.2355 - accuracy: 0.6433 - val_loss: 2.0143 - val_accuracy: 0.5016\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.2255 - accuracy: 0.6310 - val_loss: 2.0192 - val_accuracy: 0.5048\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.2378 - accuracy: 0.6447 - val_loss: 2.0404 - val_accuracy: 0.5080\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.1733 - accuracy: 0.6529 - val_loss: 2.0532 - val_accuracy: 0.5112\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.1492 - accuracy: 0.6488 - val_loss: 2.0478 - val_accuracy: 0.5080\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.1508 - accuracy: 0.6571 - val_loss: 2.0844 - val_accuracy: 0.5048\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.1441 - accuracy: 0.6406 - val_loss: 2.0487 - val_accuracy: 0.5144\n",
            "Large CNN Error: 48.56%\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Precision: 0.514\n",
            "Recall: 0.514\n",
            "Accuracy: 0.514\n",
            "F1-Score: 0.514\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  5\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 155ms/step - loss: 3.2493 - accuracy: 0.1097 - val_loss: 3.1864 - val_accuracy: 0.5080\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.1422 - accuracy: 0.4829 - val_loss: 3.0609 - val_accuracy: 0.5080\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 2.9868 - accuracy: 0.4979 - val_loss: 2.8748 - val_accuracy: 0.5080\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 2.7524 - accuracy: 0.4979 - val_loss: 2.6048 - val_accuracy: 0.5080\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.4772 - accuracy: 0.4979 - val_loss: 2.3517 - val_accuracy: 0.5080\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 2.3572 - accuracy: 0.4979 - val_loss: 2.3547 - val_accuracy: 0.5080\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.3977 - accuracy: 0.4979 - val_loss: 2.3016 - val_accuracy: 0.5080\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.3244 - accuracy: 0.4979 - val_loss: 2.2670 - val_accuracy: 0.5080\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 2.2842 - accuracy: 0.4979 - val_loss: 2.2914 - val_accuracy: 0.5080\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.2516 - accuracy: 0.4979 - val_loss: 2.2731 - val_accuracy: 0.5080\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.2327 - accuracy: 0.4979 - val_loss: 2.2286 - val_accuracy: 0.5080\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.2182 - accuracy: 0.4979 - val_loss: 2.2071 - val_accuracy: 0.5080\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 2.2001 - accuracy: 0.4979 - val_loss: 2.1982 - val_accuracy: 0.5080\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.1959 - accuracy: 0.4979 - val_loss: 2.2012 - val_accuracy: 0.5080\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.1906 - accuracy: 0.4979 - val_loss: 2.2046 - val_accuracy: 0.5080\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.1572 - accuracy: 0.4979 - val_loss: 2.1897 - val_accuracy: 0.5080\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.1601 - accuracy: 0.4979 - val_loss: 2.1772 - val_accuracy: 0.5080\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.1509 - accuracy: 0.4979 - val_loss: 2.1715 - val_accuracy: 0.5080\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.1502 - accuracy: 0.4979 - val_loss: 2.1692 - val_accuracy: 0.5080\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 2.1254 - accuracy: 0.4979 - val_loss: 2.1705 - val_accuracy: 0.5080\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.1157 - accuracy: 0.4979 - val_loss: 2.1622 - val_accuracy: 0.5080\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.1190 - accuracy: 0.4979 - val_loss: 2.1480 - val_accuracy: 0.5080\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.1129 - accuracy: 0.4979 - val_loss: 2.1446 - val_accuracy: 0.5080\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0955 - accuracy: 0.4979 - val_loss: 2.1433 - val_accuracy: 0.5080\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.1032 - accuracy: 0.4979 - val_loss: 2.1395 - val_accuracy: 0.5080\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.0794 - accuracy: 0.4979 - val_loss: 2.1301 - val_accuracy: 0.5080\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 2.0840 - accuracy: 0.4979 - val_loss: 2.1149 - val_accuracy: 0.5080\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.0683 - accuracy: 0.4979 - val_loss: 2.1220 - val_accuracy: 0.5080\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 2.0586 - accuracy: 0.4979 - val_loss: 2.1037 - val_accuracy: 0.5080\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0500 - accuracy: 0.4979 - val_loss: 2.0896 - val_accuracy: 0.5080\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0387 - accuracy: 0.4979 - val_loss: 2.0937 - val_accuracy: 0.5080\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0284 - accuracy: 0.4979 - val_loss: 2.0912 - val_accuracy: 0.5080\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0141 - accuracy: 0.4979 - val_loss: 2.0691 - val_accuracy: 0.5080\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0128 - accuracy: 0.4979 - val_loss: 2.0699 - val_accuracy: 0.5080\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9944 - accuracy: 0.4979 - val_loss: 2.0549 - val_accuracy: 0.5080\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9859 - accuracy: 0.4979 - val_loss: 2.0421 - val_accuracy: 0.5080\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.9699 - accuracy: 0.4979 - val_loss: 2.0426 - val_accuracy: 0.5080\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9475 - accuracy: 0.4979 - val_loss: 2.0248 - val_accuracy: 0.5080\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.9498 - accuracy: 0.4979 - val_loss: 2.0200 - val_accuracy: 0.5080\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9278 - accuracy: 0.4979 - val_loss: 2.0148 - val_accuracy: 0.5080\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.9014 - accuracy: 0.4979 - val_loss: 2.0043 - val_accuracy: 0.5080\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9032 - accuracy: 0.4979 - val_loss: 2.0039 - val_accuracy: 0.5080\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.8857 - accuracy: 0.4979 - val_loss: 1.9912 - val_accuracy: 0.5080\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8637 - accuracy: 0.4979 - val_loss: 1.9877 - val_accuracy: 0.5080\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8676 - accuracy: 0.4979 - val_loss: 1.9794 - val_accuracy: 0.5080\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8366 - accuracy: 0.4979 - val_loss: 1.9771 - val_accuracy: 0.5080\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.8464 - accuracy: 0.4979 - val_loss: 1.9761 - val_accuracy: 0.5080\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.8290 - accuracy: 0.4979 - val_loss: 1.9740 - val_accuracy: 0.5080\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7996 - accuracy: 0.4979 - val_loss: 1.9638 - val_accuracy: 0.5080\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7847 - accuracy: 0.4979 - val_loss: 1.9757 - val_accuracy: 0.5080\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.7902 - accuracy: 0.4979 - val_loss: 1.9604 - val_accuracy: 0.5080\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.7711 - accuracy: 0.4979 - val_loss: 1.9607 - val_accuracy: 0.5080\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.7586 - accuracy: 0.4993 - val_loss: 1.9603 - val_accuracy: 0.5080\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7440 - accuracy: 0.4979 - val_loss: 1.9477 - val_accuracy: 0.5080\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7421 - accuracy: 0.5007 - val_loss: 1.9728 - val_accuracy: 0.5080\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.7392 - accuracy: 0.5021 - val_loss: 1.9507 - val_accuracy: 0.5144\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7059 - accuracy: 0.5089 - val_loss: 1.9850 - val_accuracy: 0.5112\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6865 - accuracy: 0.5089 - val_loss: 1.9471 - val_accuracy: 0.5144\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.6922 - accuracy: 0.5089 - val_loss: 1.9622 - val_accuracy: 0.5112\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.6696 - accuracy: 0.5103 - val_loss: 1.9697 - val_accuracy: 0.5112\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6566 - accuracy: 0.5089 - val_loss: 1.9653 - val_accuracy: 0.5144\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6526 - accuracy: 0.5117 - val_loss: 1.9877 - val_accuracy: 0.5144\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6375 - accuracy: 0.5144 - val_loss: 1.9664 - val_accuracy: 0.5112\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6256 - accuracy: 0.5130 - val_loss: 1.9958 - val_accuracy: 0.5112\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6096 - accuracy: 0.5144 - val_loss: 1.9813 - val_accuracy: 0.5080\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5807 - accuracy: 0.5158 - val_loss: 2.0199 - val_accuracy: 0.5112\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.5905 - accuracy: 0.5117 - val_loss: 1.9747 - val_accuracy: 0.5112\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5720 - accuracy: 0.5171 - val_loss: 2.0535 - val_accuracy: 0.5080\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.5520 - accuracy: 0.5199 - val_loss: 1.9764 - val_accuracy: 0.5112\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.5558 - accuracy: 0.5254 - val_loss: 2.0492 - val_accuracy: 0.5048\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5384 - accuracy: 0.5213 - val_loss: 2.0046 - val_accuracy: 0.5144\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5273 - accuracy: 0.5309 - val_loss: 2.0437 - val_accuracy: 0.5080\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5027 - accuracy: 0.5364 - val_loss: 2.0493 - val_accuracy: 0.5048\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.4926 - accuracy: 0.5377 - val_loss: 2.0379 - val_accuracy: 0.5080\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.4812 - accuracy: 0.5514 - val_loss: 2.1001 - val_accuracy: 0.5080\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.4813 - accuracy: 0.5418 - val_loss: 2.0138 - val_accuracy: 0.5016\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4610 - accuracy: 0.5569 - val_loss: 2.1193 - val_accuracy: 0.5112\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4491 - accuracy: 0.5528 - val_loss: 2.0875 - val_accuracy: 0.5080\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.4370 - accuracy: 0.5652 - val_loss: 2.1533 - val_accuracy: 0.5016\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.4030 - accuracy: 0.5720 - val_loss: 2.0532 - val_accuracy: 0.5016\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.4092 - accuracy: 0.5816 - val_loss: 2.1799 - val_accuracy: 0.5080\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3793 - accuracy: 0.5761 - val_loss: 2.1172 - val_accuracy: 0.5016\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3669 - accuracy: 0.5748 - val_loss: 2.1491 - val_accuracy: 0.5208\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3414 - accuracy: 0.5748 - val_loss: 2.1423 - val_accuracy: 0.5112\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3221 - accuracy: 0.5802 - val_loss: 2.1828 - val_accuracy: 0.5048\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3425 - accuracy: 0.5871 - val_loss: 2.1420 - val_accuracy: 0.5144\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3089 - accuracy: 0.6008 - val_loss: 2.1731 - val_accuracy: 0.5144\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.2823 - accuracy: 0.6063 - val_loss: 2.2155 - val_accuracy: 0.5080\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.2851 - accuracy: 0.5981 - val_loss: 2.1421 - val_accuracy: 0.5112\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.2589 - accuracy: 0.6077 - val_loss: 2.2468 - val_accuracy: 0.5144\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.2392 - accuracy: 0.6132 - val_loss: 2.2159 - val_accuracy: 0.5144\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.2518 - accuracy: 0.6132 - val_loss: 2.2567 - val_accuracy: 0.5112\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.2297 - accuracy: 0.6187 - val_loss: 2.2460 - val_accuracy: 0.5144\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.2032 - accuracy: 0.6337 - val_loss: 2.2545 - val_accuracy: 0.5144\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.2079 - accuracy: 0.6077 - val_loss: 2.2758 - val_accuracy: 0.5112\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.1605 - accuracy: 0.6584 - val_loss: 2.3082 - val_accuracy: 0.5080\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1297 - accuracy: 0.6379 - val_loss: 2.3026 - val_accuracy: 0.5080\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1530 - accuracy: 0.6667 - val_loss: 2.4255 - val_accuracy: 0.5208\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.1248 - accuracy: 0.6543 - val_loss: 2.2756 - val_accuracy: 0.5080\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.0850 - accuracy: 0.6763 - val_loss: 2.4446 - val_accuracy: 0.5144\n",
            "Large CNN Error: 48.56%\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "Precision: 0.514\n",
            "Recall: 0.514\n",
            "Accuracy: 0.514\n",
            "F1-Score: 0.514\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  6\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 111ms/step - loss: 3.2710 - accuracy: 0.1591 - val_loss: 3.1824 - val_accuracy: 0.4920\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 3.1103 - accuracy: 0.5048 - val_loss: 2.9865 - val_accuracy: 0.4920\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.8630 - accuracy: 0.5048 - val_loss: 2.7002 - val_accuracy: 0.4920\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.5460 - accuracy: 0.5048 - val_loss: 2.3772 - val_accuracy: 0.4920\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.2668 - accuracy: 0.5048 - val_loss: 2.3438 - val_accuracy: 0.4920\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.3313 - accuracy: 0.5048 - val_loss: 2.3755 - val_accuracy: 0.4920\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.2928 - accuracy: 0.5048 - val_loss: 2.2907 - val_accuracy: 0.4920\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.2184 - accuracy: 0.5048 - val_loss: 2.3145 - val_accuracy: 0.4920\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.2247 - accuracy: 0.5048 - val_loss: 2.3245 - val_accuracy: 0.4920\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2085 - accuracy: 0.5048 - val_loss: 2.2913 - val_accuracy: 0.4920\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1876 - accuracy: 0.5048 - val_loss: 2.2691 - val_accuracy: 0.4920\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1847 - accuracy: 0.5048 - val_loss: 2.2653 - val_accuracy: 0.4920\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.1666 - accuracy: 0.5048 - val_loss: 2.2564 - val_accuracy: 0.4920\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1512 - accuracy: 0.5048 - val_loss: 2.2552 - val_accuracy: 0.4920\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.1499 - accuracy: 0.5048 - val_loss: 2.2549 - val_accuracy: 0.4920\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1423 - accuracy: 0.5048 - val_loss: 2.2417 - val_accuracy: 0.4920\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.1388 - accuracy: 0.5048 - val_loss: 2.2305 - val_accuracy: 0.4920\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1349 - accuracy: 0.5048 - val_loss: 2.2224 - val_accuracy: 0.4920\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.1269 - accuracy: 0.5048 - val_loss: 2.2203 - val_accuracy: 0.4920\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1154 - accuracy: 0.5048 - val_loss: 2.2221 - val_accuracy: 0.4920\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.1026 - accuracy: 0.5048 - val_loss: 2.2125 - val_accuracy: 0.4920\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0929 - accuracy: 0.5048 - val_loss: 2.2006 - val_accuracy: 0.4920\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0902 - accuracy: 0.5048 - val_loss: 2.1941 - val_accuracy: 0.4920\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.0756 - accuracy: 0.5048 - val_loss: 2.1929 - val_accuracy: 0.4920\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0719 - accuracy: 0.5048 - val_loss: 2.1903 - val_accuracy: 0.4920\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.0689 - accuracy: 0.5048 - val_loss: 2.1783 - val_accuracy: 0.4920\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.0565 - accuracy: 0.5048 - val_loss: 2.1723 - val_accuracy: 0.4920\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0553 - accuracy: 0.5048 - val_loss: 2.1710 - val_accuracy: 0.4920\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.0429 - accuracy: 0.5048 - val_loss: 2.1628 - val_accuracy: 0.4920\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0285 - accuracy: 0.5048 - val_loss: 2.1507 - val_accuracy: 0.4920\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0262 - accuracy: 0.5048 - val_loss: 2.1474 - val_accuracy: 0.4920\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0246 - accuracy: 0.5048 - val_loss: 2.1370 - val_accuracy: 0.4920\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.0148 - accuracy: 0.5048 - val_loss: 2.1279 - val_accuracy: 0.4920\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 2.0065 - accuracy: 0.5048 - val_loss: 2.1168 - val_accuracy: 0.4920\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.9960 - accuracy: 0.5048 - val_loss: 2.1101 - val_accuracy: 0.4920\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.9812 - accuracy: 0.5048 - val_loss: 2.1110 - val_accuracy: 0.4920\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9578 - accuracy: 0.5048 - val_loss: 2.0914 - val_accuracy: 0.4920\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9658 - accuracy: 0.5048 - val_loss: 2.0797 - val_accuracy: 0.4920\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.9447 - accuracy: 0.5048 - val_loss: 2.0768 - val_accuracy: 0.4920\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9303 - accuracy: 0.5048 - val_loss: 2.0549 - val_accuracy: 0.4920\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.9395 - accuracy: 0.5048 - val_loss: 2.0513 - val_accuracy: 0.4920\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.9103 - accuracy: 0.5048 - val_loss: 2.0438 - val_accuracy: 0.4920\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.8942 - accuracy: 0.5048 - val_loss: 2.0228 - val_accuracy: 0.4920\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.8887 - accuracy: 0.5048 - val_loss: 2.0223 - val_accuracy: 0.4920\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.8740 - accuracy: 0.5048 - val_loss: 2.0029 - val_accuracy: 0.4920\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.8591 - accuracy: 0.5048 - val_loss: 1.9978 - val_accuracy: 0.4920\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.8427 - accuracy: 0.5048 - val_loss: 1.9877 - val_accuracy: 0.4920\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.8436 - accuracy: 0.5048 - val_loss: 1.9822 - val_accuracy: 0.4920\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.8222 - accuracy: 0.5048 - val_loss: 1.9748 - val_accuracy: 0.4920\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.8023 - accuracy: 0.5048 - val_loss: 1.9704 - val_accuracy: 0.4920\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.8063 - accuracy: 0.5048 - val_loss: 1.9686 - val_accuracy: 0.4920\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.7781 - accuracy: 0.5048 - val_loss: 1.9632 - val_accuracy: 0.4920\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.7568 - accuracy: 0.5075 - val_loss: 1.9708 - val_accuracy: 0.4920\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.7475 - accuracy: 0.5089 - val_loss: 1.9589 - val_accuracy: 0.4920\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.7349 - accuracy: 0.5089 - val_loss: 1.9588 - val_accuracy: 0.4952\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.7315 - accuracy: 0.5075 - val_loss: 1.9608 - val_accuracy: 0.4952\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.7314 - accuracy: 0.5089 - val_loss: 1.9500 - val_accuracy: 0.4952\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.7159 - accuracy: 0.5103 - val_loss: 1.9904 - val_accuracy: 0.4952\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.7099 - accuracy: 0.5103 - val_loss: 1.9558 - val_accuracy: 0.4952\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6929 - accuracy: 0.5130 - val_loss: 1.9803 - val_accuracy: 0.4952\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.6917 - accuracy: 0.5117 - val_loss: 1.9749 - val_accuracy: 0.4952\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.6800 - accuracy: 0.5144 - val_loss: 1.9812 - val_accuracy: 0.4952\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.6709 - accuracy: 0.5185 - val_loss: 1.9970 - val_accuracy: 0.4952\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.6670 - accuracy: 0.5144 - val_loss: 1.9781 - val_accuracy: 0.4952\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.6679 - accuracy: 0.5171 - val_loss: 1.9920 - val_accuracy: 0.4952\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.6658 - accuracy: 0.5185 - val_loss: 2.0009 - val_accuracy: 0.4952\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6574 - accuracy: 0.5185 - val_loss: 1.9999 - val_accuracy: 0.4952\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.6480 - accuracy: 0.5213 - val_loss: 2.0177 - val_accuracy: 0.4952\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.6458 - accuracy: 0.5226 - val_loss: 2.0061 - val_accuracy: 0.4952\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6369 - accuracy: 0.5213 - val_loss: 2.0235 - val_accuracy: 0.4952\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.6424 - accuracy: 0.5240 - val_loss: 2.0355 - val_accuracy: 0.4920\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.6386 - accuracy: 0.5226 - val_loss: 2.0550 - val_accuracy: 0.4920\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.6270 - accuracy: 0.5226 - val_loss: 2.0515 - val_accuracy: 0.4920\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.6268 - accuracy: 0.5226 - val_loss: 2.0502 - val_accuracy: 0.4920\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.6213 - accuracy: 0.5226 - val_loss: 2.0809 - val_accuracy: 0.4920\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.6207 - accuracy: 0.5254 - val_loss: 2.0754 - val_accuracy: 0.4920\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6078 - accuracy: 0.5254 - val_loss: 2.0572 - val_accuracy: 0.4888\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.6085 - accuracy: 0.5226 - val_loss: 2.0942 - val_accuracy: 0.4920\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6071 - accuracy: 0.5240 - val_loss: 2.0662 - val_accuracy: 0.4888\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6093 - accuracy: 0.5254 - val_loss: 2.1208 - val_accuracy: 0.4888\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5952 - accuracy: 0.5240 - val_loss: 2.0666 - val_accuracy: 0.4888\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5931 - accuracy: 0.5267 - val_loss: 2.1572 - val_accuracy: 0.4888\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.5865 - accuracy: 0.5281 - val_loss: 2.0681 - val_accuracy: 0.4888\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5691 - accuracy: 0.5309 - val_loss: 2.1261 - val_accuracy: 0.4888\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5719 - accuracy: 0.5350 - val_loss: 2.0945 - val_accuracy: 0.4888\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.5651 - accuracy: 0.5309 - val_loss: 2.1672 - val_accuracy: 0.4888\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5485 - accuracy: 0.5309 - val_loss: 2.1144 - val_accuracy: 0.4920\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.5511 - accuracy: 0.5377 - val_loss: 2.1497 - val_accuracy: 0.4888\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5486 - accuracy: 0.5350 - val_loss: 2.1280 - val_accuracy: 0.4888\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5287 - accuracy: 0.5364 - val_loss: 2.1299 - val_accuracy: 0.4888\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5209 - accuracy: 0.5254 - val_loss: 2.1679 - val_accuracy: 0.4920\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5217 - accuracy: 0.5432 - val_loss: 2.1205 - val_accuracy: 0.4920\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4928 - accuracy: 0.5473 - val_loss: 2.2050 - val_accuracy: 0.4920\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.4969 - accuracy: 0.5418 - val_loss: 2.1461 - val_accuracy: 0.4920\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.4827 - accuracy: 0.5514 - val_loss: 2.2294 - val_accuracy: 0.4984\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4541 - accuracy: 0.5514 - val_loss: 2.1609 - val_accuracy: 0.4856\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.4379 - accuracy: 0.5652 - val_loss: 2.1902 - val_accuracy: 0.4920\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.4370 - accuracy: 0.5569 - val_loss: 2.1883 - val_accuracy: 0.4920\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.3964 - accuracy: 0.5816 - val_loss: 2.1998 - val_accuracy: 0.4984\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3830 - accuracy: 0.5748 - val_loss: 2.2118 - val_accuracy: 0.4824\n",
            "Large CNN Error: 51.76%\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "Precision: 0.482\n",
            "Recall: 0.482\n",
            "Accuracy: 0.482\n",
            "F1-Score: 0.482\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  7\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 150ms/step - loss: 3.2592 - accuracy: 0.1481 - val_loss: 3.1558 - val_accuracy: 0.4888\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 3.0858 - accuracy: 0.4979 - val_loss: 2.9732 - val_accuracy: 0.4888\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.8704 - accuracy: 0.5062 - val_loss: 2.7041 - val_accuracy: 0.4888\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 2.5650 - accuracy: 0.5062 - val_loss: 2.4065 - val_accuracy: 0.4888\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.3390 - accuracy: 0.5062 - val_loss: 2.3449 - val_accuracy: 0.4888\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.3650 - accuracy: 0.5062 - val_loss: 2.3626 - val_accuracy: 0.4888\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.3331 - accuracy: 0.5062 - val_loss: 2.2997 - val_accuracy: 0.4888\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.2350 - accuracy: 0.5062 - val_loss: 2.3173 - val_accuracy: 0.4888\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.2293 - accuracy: 0.5062 - val_loss: 2.3223 - val_accuracy: 0.4888\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.2297 - accuracy: 0.5062 - val_loss: 2.3005 - val_accuracy: 0.4888\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.1905 - accuracy: 0.5062 - val_loss: 2.2772 - val_accuracy: 0.4888\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.1768 - accuracy: 0.5062 - val_loss: 2.2707 - val_accuracy: 0.4888\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.1721 - accuracy: 0.5062 - val_loss: 2.2660 - val_accuracy: 0.4888\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 2.1579 - accuracy: 0.5062 - val_loss: 2.2730 - val_accuracy: 0.4888\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.1541 - accuracy: 0.5062 - val_loss: 2.2729 - val_accuracy: 0.4888\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.1346 - accuracy: 0.5062 - val_loss: 2.2593 - val_accuracy: 0.4888\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.1251 - accuracy: 0.5062 - val_loss: 2.2505 - val_accuracy: 0.4888\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.1117 - accuracy: 0.5062 - val_loss: 2.2424 - val_accuracy: 0.4888\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 2.1072 - accuracy: 0.5062 - val_loss: 2.2429 - val_accuracy: 0.4888\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 2.0995 - accuracy: 0.5062 - val_loss: 2.2391 - val_accuracy: 0.4888\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.0946 - accuracy: 0.5062 - val_loss: 2.2297 - val_accuracy: 0.4888\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.0794 - accuracy: 0.5062 - val_loss: 2.2218 - val_accuracy: 0.4888\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 2.0709 - accuracy: 0.5062 - val_loss: 2.2192 - val_accuracy: 0.4888\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.0624 - accuracy: 0.5062 - val_loss: 2.2070 - val_accuracy: 0.4888\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.0538 - accuracy: 0.5062 - val_loss: 2.1983 - val_accuracy: 0.4888\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.0394 - accuracy: 0.5062 - val_loss: 2.1946 - val_accuracy: 0.4888\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0256 - accuracy: 0.5062 - val_loss: 2.1871 - val_accuracy: 0.4888\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0177 - accuracy: 0.5062 - val_loss: 2.1820 - val_accuracy: 0.4888\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0047 - accuracy: 0.5062 - val_loss: 2.1733 - val_accuracy: 0.4888\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9928 - accuracy: 0.5062 - val_loss: 2.1624 - val_accuracy: 0.4888\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.9830 - accuracy: 0.5062 - val_loss: 2.1557 - val_accuracy: 0.4888\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.9684 - accuracy: 0.5062 - val_loss: 2.1400 - val_accuracy: 0.4888\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.9450 - accuracy: 0.5062 - val_loss: 2.1387 - val_accuracy: 0.4888\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.9471 - accuracy: 0.5062 - val_loss: 2.1338 - val_accuracy: 0.4888\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9291 - accuracy: 0.5062 - val_loss: 2.1129 - val_accuracy: 0.4888\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8952 - accuracy: 0.5062 - val_loss: 2.1174 - val_accuracy: 0.4888\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9017 - accuracy: 0.5062 - val_loss: 2.0972 - val_accuracy: 0.4888\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.8879 - accuracy: 0.5062 - val_loss: 2.0904 - val_accuracy: 0.4888\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8698 - accuracy: 0.5062 - val_loss: 2.0880 - val_accuracy: 0.4888\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8600 - accuracy: 0.5062 - val_loss: 2.0705 - val_accuracy: 0.4888\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8371 - accuracy: 0.5062 - val_loss: 2.0863 - val_accuracy: 0.4888\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8224 - accuracy: 0.5062 - val_loss: 2.0562 - val_accuracy: 0.4888\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.8107 - accuracy: 0.5062 - val_loss: 2.0586 - val_accuracy: 0.4888\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7997 - accuracy: 0.5062 - val_loss: 2.0504 - val_accuracy: 0.4888\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7961 - accuracy: 0.5062 - val_loss: 2.0490 - val_accuracy: 0.4888\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7954 - accuracy: 0.5062 - val_loss: 2.0443 - val_accuracy: 0.4888\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.7773 - accuracy: 0.5062 - val_loss: 2.0398 - val_accuracy: 0.4888\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7577 - accuracy: 0.5062 - val_loss: 2.0442 - val_accuracy: 0.4888\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7496 - accuracy: 0.5075 - val_loss: 2.0369 - val_accuracy: 0.4888\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7386 - accuracy: 0.5062 - val_loss: 2.0360 - val_accuracy: 0.4888\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7268 - accuracy: 0.5075 - val_loss: 2.0396 - val_accuracy: 0.4888\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7217 - accuracy: 0.5089 - val_loss: 2.0450 - val_accuracy: 0.4888\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7234 - accuracy: 0.5103 - val_loss: 2.0514 - val_accuracy: 0.4888\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7022 - accuracy: 0.5089 - val_loss: 2.0400 - val_accuracy: 0.4888\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.6919 - accuracy: 0.5089 - val_loss: 2.0418 - val_accuracy: 0.4920\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.6949 - accuracy: 0.5103 - val_loss: 2.0468 - val_accuracy: 0.4920\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6919 - accuracy: 0.5075 - val_loss: 2.0358 - val_accuracy: 0.4920\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6766 - accuracy: 0.5130 - val_loss: 2.0431 - val_accuracy: 0.4920\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.6719 - accuracy: 0.5103 - val_loss: 2.0432 - val_accuracy: 0.4920\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.6708 - accuracy: 0.5158 - val_loss: 2.0463 - val_accuracy: 0.4920\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.6555 - accuracy: 0.5185 - val_loss: 2.0607 - val_accuracy: 0.4920\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6596 - accuracy: 0.5199 - val_loss: 2.0756 - val_accuracy: 0.4984\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.6408 - accuracy: 0.5117 - val_loss: 2.0529 - val_accuracy: 0.4888\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6418 - accuracy: 0.5267 - val_loss: 2.0637 - val_accuracy: 0.4888\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.6493 - accuracy: 0.5199 - val_loss: 2.0893 - val_accuracy: 0.4952\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.6298 - accuracy: 0.5350 - val_loss: 2.0666 - val_accuracy: 0.4824\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6224 - accuracy: 0.5226 - val_loss: 2.1134 - val_accuracy: 0.4888\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6274 - accuracy: 0.5322 - val_loss: 2.0834 - val_accuracy: 0.4888\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6138 - accuracy: 0.5254 - val_loss: 2.1134 - val_accuracy: 0.4888\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6127 - accuracy: 0.5295 - val_loss: 2.0831 - val_accuracy: 0.4920\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5986 - accuracy: 0.5309 - val_loss: 2.1432 - val_accuracy: 0.4952\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.5953 - accuracy: 0.5336 - val_loss: 2.1119 - val_accuracy: 0.4888\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5933 - accuracy: 0.5405 - val_loss: 2.1651 - val_accuracy: 0.4888\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5691 - accuracy: 0.5432 - val_loss: 2.1276 - val_accuracy: 0.4888\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.5768 - accuracy: 0.5350 - val_loss: 2.1687 - val_accuracy: 0.4888\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.5618 - accuracy: 0.5418 - val_loss: 2.1649 - val_accuracy: 0.4888\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5416 - accuracy: 0.5501 - val_loss: 2.1777 - val_accuracy: 0.4856\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.5419 - accuracy: 0.5432 - val_loss: 2.1918 - val_accuracy: 0.4856\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5250 - accuracy: 0.5473 - val_loss: 2.1798 - val_accuracy: 0.4856\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5053 - accuracy: 0.5487 - val_loss: 2.2175 - val_accuracy: 0.4856\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4989 - accuracy: 0.5446 - val_loss: 2.1569 - val_accuracy: 0.4824\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.4882 - accuracy: 0.5473 - val_loss: 2.2961 - val_accuracy: 0.4952\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.4652 - accuracy: 0.5569 - val_loss: 2.2110 - val_accuracy: 0.4824\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4521 - accuracy: 0.5556 - val_loss: 2.2397 - val_accuracy: 0.4824\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.4111 - accuracy: 0.5638 - val_loss: 2.3613 - val_accuracy: 0.4920\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.4160 - accuracy: 0.5652 - val_loss: 2.2013 - val_accuracy: 0.4633\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4067 - accuracy: 0.5748 - val_loss: 2.4486 - val_accuracy: 0.4984\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.4049 - accuracy: 0.5652 - val_loss: 2.3082 - val_accuracy: 0.4824\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3739 - accuracy: 0.5748 - val_loss: 2.2701 - val_accuracy: 0.4665\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3681 - accuracy: 0.5789 - val_loss: 2.3776 - val_accuracy: 0.4952\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3308 - accuracy: 0.5940 - val_loss: 2.3183 - val_accuracy: 0.4792\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3113 - accuracy: 0.5981 - val_loss: 2.4353 - val_accuracy: 0.4856\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.3136 - accuracy: 0.6008 - val_loss: 2.3108 - val_accuracy: 0.4824\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.2880 - accuracy: 0.6008 - val_loss: 2.3888 - val_accuracy: 0.4824\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.2499 - accuracy: 0.6228 - val_loss: 2.5243 - val_accuracy: 0.4952\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.2500 - accuracy: 0.6104 - val_loss: 2.3386 - val_accuracy: 0.4792\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.2577 - accuracy: 0.6241 - val_loss: 2.5381 - val_accuracy: 0.4952\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.2307 - accuracy: 0.6118 - val_loss: 2.5413 - val_accuracy: 0.4920\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.2189 - accuracy: 0.6228 - val_loss: 2.4120 - val_accuracy: 0.4824\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.2009 - accuracy: 0.6365 - val_loss: 2.5645 - val_accuracy: 0.5048\n",
            "Large CNN Error: 49.52%\n",
            "10/10 [==============================] - 0s 7ms/step\n",
            "Precision: 0.505\n",
            "Recall: 0.505\n",
            "Accuracy: 0.505\n",
            "F1-Score: 0.505\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  8\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 2s 106ms/step - loss: 3.2748 - accuracy: 0.1015 - val_loss: 3.2168 - val_accuracy: 0.4984\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 3.1720 - accuracy: 0.4938 - val_loss: 3.0814 - val_accuracy: 0.4984\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 3.0019 - accuracy: 0.5021 - val_loss: 2.8672 - val_accuracy: 0.4984\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.7339 - accuracy: 0.5021 - val_loss: 2.5767 - val_accuracy: 0.4984\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.4373 - accuracy: 0.5021 - val_loss: 2.3277 - val_accuracy: 0.4984\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2892 - accuracy: 0.5021 - val_loss: 2.3655 - val_accuracy: 0.4984\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.3705 - accuracy: 0.5021 - val_loss: 2.3243 - val_accuracy: 0.4984\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2614 - accuracy: 0.5021 - val_loss: 2.2688 - val_accuracy: 0.4984\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2269 - accuracy: 0.5021 - val_loss: 2.2874 - val_accuracy: 0.4984\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.2364 - accuracy: 0.5021 - val_loss: 2.2893 - val_accuracy: 0.4984\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.2099 - accuracy: 0.5021 - val_loss: 2.2550 - val_accuracy: 0.4984\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1925 - accuracy: 0.5021 - val_loss: 2.2341 - val_accuracy: 0.4984\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1829 - accuracy: 0.5021 - val_loss: 2.2296 - val_accuracy: 0.4984\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.1950 - accuracy: 0.5021 - val_loss: 2.2209 - val_accuracy: 0.4984\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1582 - accuracy: 0.5021 - val_loss: 2.2194 - val_accuracy: 0.4984\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1573 - accuracy: 0.5021 - val_loss: 2.2163 - val_accuracy: 0.4984\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.1446 - accuracy: 0.5021 - val_loss: 2.2043 - val_accuracy: 0.4984\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1344 - accuracy: 0.5021 - val_loss: 2.1936 - val_accuracy: 0.4984\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.1277 - accuracy: 0.5021 - val_loss: 2.1859 - val_accuracy: 0.4984\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.1263 - accuracy: 0.5021 - val_loss: 2.1822 - val_accuracy: 0.4984\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.1163 - accuracy: 0.5021 - val_loss: 2.1769 - val_accuracy: 0.4984\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1150 - accuracy: 0.5021 - val_loss: 2.1683 - val_accuracy: 0.4984\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1010 - accuracy: 0.5021 - val_loss: 2.1623 - val_accuracy: 0.4984\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0838 - accuracy: 0.5021 - val_loss: 2.1617 - val_accuracy: 0.4984\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0831 - accuracy: 0.5021 - val_loss: 2.1580 - val_accuracy: 0.4984\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.0764 - accuracy: 0.5021 - val_loss: 2.1422 - val_accuracy: 0.4984\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.0727 - accuracy: 0.5021 - val_loss: 2.1318 - val_accuracy: 0.4984\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.0545 - accuracy: 0.5021 - val_loss: 2.1334 - val_accuracy: 0.4984\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0438 - accuracy: 0.5021 - val_loss: 2.1322 - val_accuracy: 0.4984\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0380 - accuracy: 0.5021 - val_loss: 2.1138 - val_accuracy: 0.4984\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0333 - accuracy: 0.5021 - val_loss: 2.1067 - val_accuracy: 0.4984\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.0167 - accuracy: 0.5021 - val_loss: 2.1012 - val_accuracy: 0.4984\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0030 - accuracy: 0.5021 - val_loss: 2.0876 - val_accuracy: 0.4984\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.9872 - accuracy: 0.5021 - val_loss: 2.0832 - val_accuracy: 0.4984\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.9842 - accuracy: 0.5021 - val_loss: 2.0794 - val_accuracy: 0.4984\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9596 - accuracy: 0.5021 - val_loss: 2.0653 - val_accuracy: 0.4984\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9545 - accuracy: 0.5021 - val_loss: 2.0563 - val_accuracy: 0.4984\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.9521 - accuracy: 0.5021 - val_loss: 2.0520 - val_accuracy: 0.4984\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.9320 - accuracy: 0.5021 - val_loss: 2.0408 - val_accuracy: 0.4984\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9007 - accuracy: 0.5021 - val_loss: 2.0310 - val_accuracy: 0.4984\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9033 - accuracy: 0.5021 - val_loss: 2.0233 - val_accuracy: 0.4984\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.8899 - accuracy: 0.5021 - val_loss: 2.0154 - val_accuracy: 0.4984\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8779 - accuracy: 0.5021 - val_loss: 2.0095 - val_accuracy: 0.4984\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.8659 - accuracy: 0.5021 - val_loss: 2.0032 - val_accuracy: 0.4984\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.8503 - accuracy: 0.5021 - val_loss: 1.9957 - val_accuracy: 0.4984\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.8438 - accuracy: 0.5021 - val_loss: 1.9885 - val_accuracy: 0.4984\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.8303 - accuracy: 0.5021 - val_loss: 1.9866 - val_accuracy: 0.4984\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.8075 - accuracy: 0.5021 - val_loss: 1.9843 - val_accuracy: 0.4984\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.8047 - accuracy: 0.5034 - val_loss: 1.9755 - val_accuracy: 0.5016\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.7990 - accuracy: 0.5034 - val_loss: 1.9844 - val_accuracy: 0.5016\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7834 - accuracy: 0.5075 - val_loss: 1.9793 - val_accuracy: 0.5016\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.7700 - accuracy: 0.5158 - val_loss: 1.9688 - val_accuracy: 0.4984\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7619 - accuracy: 0.5185 - val_loss: 1.9821 - val_accuracy: 0.4984\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.7574 - accuracy: 0.5117 - val_loss: 1.9590 - val_accuracy: 0.4984\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.7215 - accuracy: 0.5171 - val_loss: 1.9787 - val_accuracy: 0.4984\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.7210 - accuracy: 0.5171 - val_loss: 1.9547 - val_accuracy: 0.4984\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7080 - accuracy: 0.5226 - val_loss: 1.9741 - val_accuracy: 0.4952\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.6986 - accuracy: 0.5240 - val_loss: 1.9604 - val_accuracy: 0.4984\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6934 - accuracy: 0.5240 - val_loss: 1.9727 - val_accuracy: 0.4984\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6665 - accuracy: 0.5199 - val_loss: 1.9613 - val_accuracy: 0.4952\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6545 - accuracy: 0.5267 - val_loss: 1.9873 - val_accuracy: 0.4984\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.6761 - accuracy: 0.5267 - val_loss: 1.9677 - val_accuracy: 0.4984\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.6506 - accuracy: 0.5281 - val_loss: 1.9793 - val_accuracy: 0.4952\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.6471 - accuracy: 0.5185 - val_loss: 1.9757 - val_accuracy: 0.4952\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.6316 - accuracy: 0.5267 - val_loss: 2.0019 - val_accuracy: 0.4952\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.6266 - accuracy: 0.5322 - val_loss: 1.9895 - val_accuracy: 0.4920\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.6000 - accuracy: 0.5322 - val_loss: 1.9937 - val_accuracy: 0.4920\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.6045 - accuracy: 0.5254 - val_loss: 1.9742 - val_accuracy: 0.4920\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.5960 - accuracy: 0.5295 - val_loss: 2.0167 - val_accuracy: 0.4952\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.5683 - accuracy: 0.5336 - val_loss: 1.9857 - val_accuracy: 0.4920\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.5608 - accuracy: 0.5350 - val_loss: 2.0124 - val_accuracy: 0.5048\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 1.5421 - accuracy: 0.5391 - val_loss: 1.9651 - val_accuracy: 0.4984\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.5416 - accuracy: 0.5418 - val_loss: 2.0205 - val_accuracy: 0.4952\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.5353 - accuracy: 0.5377 - val_loss: 2.0113 - val_accuracy: 0.5016\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5001 - accuracy: 0.5446 - val_loss: 2.0268 - val_accuracy: 0.5112\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.4790 - accuracy: 0.5638 - val_loss: 2.0101 - val_accuracy: 0.5112\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.4679 - accuracy: 0.5665 - val_loss: 1.9558 - val_accuracy: 0.5112\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.4712 - accuracy: 0.5638 - val_loss: 2.0198 - val_accuracy: 0.5176\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.4184 - accuracy: 0.5624 - val_loss: 1.9865 - val_accuracy: 0.5016\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.4165 - accuracy: 0.5830 - val_loss: 2.0269 - val_accuracy: 0.5080\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.3834 - accuracy: 0.5816 - val_loss: 1.9910 - val_accuracy: 0.5048\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.3674 - accuracy: 0.5885 - val_loss: 1.9904 - val_accuracy: 0.5048\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.3914 - accuracy: 0.5995 - val_loss: 2.0869 - val_accuracy: 0.5048\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.3574 - accuracy: 0.6008 - val_loss: 1.9533 - val_accuracy: 0.5144\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.3108 - accuracy: 0.6132 - val_loss: 2.1068 - val_accuracy: 0.5208\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.2901 - accuracy: 0.6351 - val_loss: 1.9752 - val_accuracy: 0.5240\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.2836 - accuracy: 0.6214 - val_loss: 2.0700 - val_accuracy: 0.5272\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.3016 - accuracy: 0.6036 - val_loss: 2.0523 - val_accuracy: 0.5335\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.2542 - accuracy: 0.6269 - val_loss: 2.0688 - val_accuracy: 0.5272\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.2405 - accuracy: 0.6214 - val_loss: 2.1678 - val_accuracy: 0.5431\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.2292 - accuracy: 0.6337 - val_loss: 2.0916 - val_accuracy: 0.5335\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.1746 - accuracy: 0.6516 - val_loss: 2.1066 - val_accuracy: 0.5431\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.2079 - accuracy: 0.6502 - val_loss: 2.1246 - val_accuracy: 0.5463\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1602 - accuracy: 0.6392 - val_loss: 2.1270 - val_accuracy: 0.5399\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.1801 - accuracy: 0.6447 - val_loss: 2.1665 - val_accuracy: 0.5431\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.1411 - accuracy: 0.6488 - val_loss: 2.1510 - val_accuracy: 0.5527\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.1327 - accuracy: 0.6516 - val_loss: 2.1366 - val_accuracy: 0.5463\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.0946 - accuracy: 0.6680 - val_loss: 2.1662 - val_accuracy: 0.5559\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.0902 - accuracy: 0.6708 - val_loss: 2.1275 - val_accuracy: 0.5527\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.1041 - accuracy: 0.6694 - val_loss: 2.2364 - val_accuracy: 0.5559\n",
            "Large CNN Error: 44.41%\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "Precision: 0.556\n",
            "Recall: 0.556\n",
            "Accuracy: 0.556\n",
            "F1-Score: 0.556\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  9\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 105ms/step - loss: 3.2251 - accuracy: 0.0219 - val_loss: 3.1236 - val_accuracy: 0.1821\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 3.0464 - accuracy: 0.3759 - val_loss: 2.8953 - val_accuracy: 0.5016\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.8041 - accuracy: 0.5007 - val_loss: 2.5899 - val_accuracy: 0.5016\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.5023 - accuracy: 0.5007 - val_loss: 2.3529 - val_accuracy: 0.5016\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 2.4063 - accuracy: 0.5007 - val_loss: 2.3744 - val_accuracy: 0.5016\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.3910 - accuracy: 0.5007 - val_loss: 2.2973 - val_accuracy: 0.5016\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.3056 - accuracy: 0.5007 - val_loss: 2.2721 - val_accuracy: 0.5016\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.2735 - accuracy: 0.5007 - val_loss: 2.2862 - val_accuracy: 0.5016\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.2451 - accuracy: 0.5007 - val_loss: 2.2518 - val_accuracy: 0.5016\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2435 - accuracy: 0.5007 - val_loss: 2.2263 - val_accuracy: 0.5016\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.2167 - accuracy: 0.5007 - val_loss: 2.2193 - val_accuracy: 0.5016\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.1960 - accuracy: 0.5007 - val_loss: 2.2117 - val_accuracy: 0.5016\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1890 - accuracy: 0.5007 - val_loss: 2.2157 - val_accuracy: 0.5016\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1788 - accuracy: 0.5007 - val_loss: 2.2059 - val_accuracy: 0.5016\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1666 - accuracy: 0.5007 - val_loss: 2.1940 - val_accuracy: 0.5016\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.1568 - accuracy: 0.5007 - val_loss: 2.1881 - val_accuracy: 0.5016\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1373 - accuracy: 0.5007 - val_loss: 2.1839 - val_accuracy: 0.5016\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.1260 - accuracy: 0.5007 - val_loss: 2.1791 - val_accuracy: 0.5016\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1228 - accuracy: 0.5007 - val_loss: 2.1704 - val_accuracy: 0.5016\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1118 - accuracy: 0.5007 - val_loss: 2.1627 - val_accuracy: 0.5016\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.1031 - accuracy: 0.5007 - val_loss: 2.1561 - val_accuracy: 0.5016\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0833 - accuracy: 0.5007 - val_loss: 2.1465 - val_accuracy: 0.5016\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0766 - accuracy: 0.5007 - val_loss: 2.1428 - val_accuracy: 0.5016\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0704 - accuracy: 0.5007 - val_loss: 2.1360 - val_accuracy: 0.5016\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.0582 - accuracy: 0.5007 - val_loss: 2.1255 - val_accuracy: 0.5016\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 2.0602 - accuracy: 0.5007 - val_loss: 2.1167 - val_accuracy: 0.5016\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 2.0361 - accuracy: 0.5007 - val_loss: 2.1133 - val_accuracy: 0.5016\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 2.0280 - accuracy: 0.5007 - val_loss: 2.1080 - val_accuracy: 0.5016\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 2.0169 - accuracy: 0.5007 - val_loss: 2.0969 - val_accuracy: 0.5016\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 2.0076 - accuracy: 0.5007 - val_loss: 2.0877 - val_accuracy: 0.5016\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.9995 - accuracy: 0.5007 - val_loss: 2.0839 - val_accuracy: 0.5016\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 1.9842 - accuracy: 0.5007 - val_loss: 2.0818 - val_accuracy: 0.5016\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 1.9736 - accuracy: 0.5007 - val_loss: 2.0684 - val_accuracy: 0.5016\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 1.9664 - accuracy: 0.5007 - val_loss: 2.0640 - val_accuracy: 0.5016\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 1.9456 - accuracy: 0.5007 - val_loss: 2.0538 - val_accuracy: 0.5016\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.9414 - accuracy: 0.5007 - val_loss: 2.0463 - val_accuracy: 0.5016\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.9340 - accuracy: 0.5007 - val_loss: 2.0409 - val_accuracy: 0.5016\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.9017 - accuracy: 0.5007 - val_loss: 2.0351 - val_accuracy: 0.5016\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.8916 - accuracy: 0.5007 - val_loss: 2.0247 - val_accuracy: 0.5016\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 1.8790 - accuracy: 0.5007 - val_loss: 2.0186 - val_accuracy: 0.5016\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.8675 - accuracy: 0.5007 - val_loss: 2.0276 - val_accuracy: 0.5016\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.8445 - accuracy: 0.5007 - val_loss: 2.0059 - val_accuracy: 0.5016\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.8555 - accuracy: 0.5007 - val_loss: 1.9999 - val_accuracy: 0.5016\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.8196 - accuracy: 0.5007 - val_loss: 2.0100 - val_accuracy: 0.5016\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.8160 - accuracy: 0.5007 - val_loss: 1.9941 - val_accuracy: 0.5016\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.8051 - accuracy: 0.5007 - val_loss: 1.9949 - val_accuracy: 0.5016\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.7896 - accuracy: 0.5021 - val_loss: 1.9892 - val_accuracy: 0.5016\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.7769 - accuracy: 0.5021 - val_loss: 1.9973 - val_accuracy: 0.5016\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.7600 - accuracy: 0.5034 - val_loss: 1.9889 - val_accuracy: 0.5016\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.7479 - accuracy: 0.5034 - val_loss: 1.9883 - val_accuracy: 0.5016\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.7417 - accuracy: 0.5021 - val_loss: 1.9933 - val_accuracy: 0.5016\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.7361 - accuracy: 0.5021 - val_loss: 1.9927 - val_accuracy: 0.5016\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.7305 - accuracy: 0.5062 - val_loss: 1.9975 - val_accuracy: 0.5016\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7120 - accuracy: 0.5062 - val_loss: 1.9942 - val_accuracy: 0.5016\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.7082 - accuracy: 0.5048 - val_loss: 2.0206 - val_accuracy: 0.5016\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.7026 - accuracy: 0.5075 - val_loss: 1.9955 - val_accuracy: 0.5016\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6925 - accuracy: 0.5117 - val_loss: 2.0422 - val_accuracy: 0.5048\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.6790 - accuracy: 0.5171 - val_loss: 1.9912 - val_accuracy: 0.5016\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6779 - accuracy: 0.5117 - val_loss: 2.0427 - val_accuracy: 0.5048\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.6753 - accuracy: 0.5089 - val_loss: 2.0192 - val_accuracy: 0.5016\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6641 - accuracy: 0.5144 - val_loss: 2.0138 - val_accuracy: 0.5048\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6571 - accuracy: 0.5213 - val_loss: 2.0548 - val_accuracy: 0.5048\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.6479 - accuracy: 0.5185 - val_loss: 2.0427 - val_accuracy: 0.5048\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6393 - accuracy: 0.5158 - val_loss: 2.0503 - val_accuracy: 0.5048\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.6314 - accuracy: 0.5226 - val_loss: 2.0923 - val_accuracy: 0.5048\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6322 - accuracy: 0.5213 - val_loss: 2.0367 - val_accuracy: 0.5080\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.6280 - accuracy: 0.5267 - val_loss: 2.0761 - val_accuracy: 0.5080\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6176 - accuracy: 0.5226 - val_loss: 2.0520 - val_accuracy: 0.5112\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.6035 - accuracy: 0.5281 - val_loss: 2.0909 - val_accuracy: 0.5080\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.6029 - accuracy: 0.5267 - val_loss: 2.0776 - val_accuracy: 0.5112\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5987 - accuracy: 0.5281 - val_loss: 2.0791 - val_accuracy: 0.5080\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5882 - accuracy: 0.5364 - val_loss: 2.1887 - val_accuracy: 0.5112\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.5904 - accuracy: 0.5322 - val_loss: 2.0381 - val_accuracy: 0.5016\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5818 - accuracy: 0.5514 - val_loss: 2.2060 - val_accuracy: 0.5048\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5669 - accuracy: 0.5309 - val_loss: 2.0547 - val_accuracy: 0.5016\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5542 - accuracy: 0.5528 - val_loss: 2.1833 - val_accuracy: 0.5080\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.5417 - accuracy: 0.5432 - val_loss: 2.0685 - val_accuracy: 0.5048\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.5377 - accuracy: 0.5638 - val_loss: 2.1684 - val_accuracy: 0.5048\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.5058 - accuracy: 0.5432 - val_loss: 2.0958 - val_accuracy: 0.4984\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.5062 - accuracy: 0.5556 - val_loss: 2.1707 - val_accuracy: 0.5016\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.5069 - accuracy: 0.5487 - val_loss: 2.0757 - val_accuracy: 0.5048\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.4850 - accuracy: 0.5761 - val_loss: 2.2210 - val_accuracy: 0.5048\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.4545 - accuracy: 0.5652 - val_loss: 2.0980 - val_accuracy: 0.5112\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.4287 - accuracy: 0.6008 - val_loss: 2.1682 - val_accuracy: 0.5080\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4098 - accuracy: 0.5789 - val_loss: 2.1415 - val_accuracy: 0.5176\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3990 - accuracy: 0.5898 - val_loss: 2.1866 - val_accuracy: 0.5112\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3648 - accuracy: 0.6187 - val_loss: 2.1677 - val_accuracy: 0.5112\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3461 - accuracy: 0.6159 - val_loss: 2.1261 - val_accuracy: 0.5144\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3322 - accuracy: 0.6214 - val_loss: 2.2251 - val_accuracy: 0.5208\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.2997 - accuracy: 0.6255 - val_loss: 2.1137 - val_accuracy: 0.5080\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.2553 - accuracy: 0.6461 - val_loss: 2.2336 - val_accuracy: 0.5144\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.2523 - accuracy: 0.6337 - val_loss: 2.1063 - val_accuracy: 0.5144\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.2292 - accuracy: 0.6420 - val_loss: 2.3192 - val_accuracy: 0.5208\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.2022 - accuracy: 0.6529 - val_loss: 2.1150 - val_accuracy: 0.5240\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.1912 - accuracy: 0.6420 - val_loss: 2.2873 - val_accuracy: 0.5176\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.1728 - accuracy: 0.6598 - val_loss: 2.1979 - val_accuracy: 0.5240\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.1428 - accuracy: 0.6667 - val_loss: 2.1965 - val_accuracy: 0.5176\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.1062 - accuracy: 0.6845 - val_loss: 2.3081 - val_accuracy: 0.5208\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.0980 - accuracy: 0.6694 - val_loss: 2.2962 - val_accuracy: 0.5240\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.0546 - accuracy: 0.6886 - val_loss: 2.3211 - val_accuracy: 0.5176\n",
            "Large CNN Error: 48.24%\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Precision: 0.518\n",
            "Recall: 0.518\n",
            "Accuracy: 0.518\n",
            "F1-Score: 0.518\n",
            "[0.07028247 0.06331392 0.05500946 0.04903478 0.03831073 0.03453505\n",
            " 0.03290767 0.02823806 0.02506891 0.02444214 0.02205497 0.02103395\n",
            " 0.02091311 0.01974121 0.01915328 0.017315   0.01624746 0.0151351\n",
            " 0.01414199 0.01375712 0.01259448 0.0121061  0.01081763 0.01035144\n",
            " 0.00953503 0.00925663 0.00899885 0.00830912 0.00822452 0.00763748\n",
            " 0.00761062 0.00701223 0.00694361 0.00657874 0.00628694 0.00608748\n",
            " 0.00569699 0.00561422 0.00548366 0.005344   0.00502707 0.00466896\n",
            " 0.00456014 0.00444149 0.00440237 0.00426995 0.00416495 0.00403307\n",
            " 0.00397105 0.00367785 0.00351003 0.00345147 0.00326903 0.00323571\n",
            " 0.00318903 0.00317982 0.00306018 0.00287875 0.00279957 0.00271976\n",
            " 0.00266548 0.00256627 0.00251081 0.00241849 0.00237476 0.00236363\n",
            " 0.00232722 0.00226425 0.00221627 0.00215724 0.0020724  0.00201313\n",
            " 0.00198702 0.00193312 0.0018714  0.00183649 0.0017955  0.0017574\n",
            " 0.00173949 0.00164137 0.00162968 0.00157345 0.00156059 0.00149845\n",
            " 0.00148048 0.00146605 0.00144418 0.00140567 0.0013908  0.00136738\n",
            " 0.00134965 0.00133079 0.00130937 0.00126567 0.00123635 0.00119792\n",
            " 0.00118974 0.00117788 0.00115514 0.00114798 0.00112864 0.0011134\n",
            " 0.00109384 0.00107011 0.00106273 0.0010462  0.00103676 0.00103014\n",
            " 0.00099265 0.00098392 0.00096717 0.00096015 0.0009397  0.00092905\n",
            " 0.0009182  0.0009047  0.00088031 0.00087442 0.00085922 0.00085722\n",
            " 0.00083845 0.00081935 0.0008046  0.00079324 0.00077479 0.00076499\n",
            " 0.00076403 0.00076051 0.00074769 0.00073353 0.00072488 0.00071724\n",
            " 0.00071052 0.00070315 0.00069527 0.00069236 0.00068058 0.00067025\n",
            " 0.00066295 0.00065922 0.00065391 0.00064715 0.00062993 0.00062508]\n",
            "144\n",
            "12 12\n",
            "FOLD NO:  10\n",
            "input shape (12, 12, 1)\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 3s 141ms/step - loss: 3.2487 - accuracy: 0.1468 - val_loss: 3.1893 - val_accuracy: 0.4185\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 3.1334 - accuracy: 0.4568 - val_loss: 3.0437 - val_accuracy: 0.4856\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.9372 - accuracy: 0.5075 - val_loss: 2.8149 - val_accuracy: 0.4856\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.6583 - accuracy: 0.5075 - val_loss: 2.5217 - val_accuracy: 0.4856\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.3608 - accuracy: 0.5075 - val_loss: 2.3883 - val_accuracy: 0.4856\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.3874 - accuracy: 0.5075 - val_loss: 2.4546 - val_accuracy: 0.4856\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.3358 - accuracy: 0.5075 - val_loss: 2.3480 - val_accuracy: 0.4856\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.2373 - accuracy: 0.5075 - val_loss: 2.3237 - val_accuracy: 0.4856\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2433 - accuracy: 0.5075 - val_loss: 2.3377 - val_accuracy: 0.4856\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2283 - accuracy: 0.5075 - val_loss: 2.3143 - val_accuracy: 0.4856\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.2051 - accuracy: 0.5075 - val_loss: 2.2819 - val_accuracy: 0.4856\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.2004 - accuracy: 0.5075 - val_loss: 2.2725 - val_accuracy: 0.4856\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.1780 - accuracy: 0.5075 - val_loss: 2.2649 - val_accuracy: 0.4856\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1568 - accuracy: 0.5075 - val_loss: 2.2616 - val_accuracy: 0.4856\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1564 - accuracy: 0.5075 - val_loss: 2.2666 - val_accuracy: 0.4856\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1491 - accuracy: 0.5075 - val_loss: 2.2591 - val_accuracy: 0.4856\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.1313 - accuracy: 0.5075 - val_loss: 2.2496 - val_accuracy: 0.4856\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1272 - accuracy: 0.5075 - val_loss: 2.2456 - val_accuracy: 0.4856\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1262 - accuracy: 0.5075 - val_loss: 2.2481 - val_accuracy: 0.4856\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.1054 - accuracy: 0.5075 - val_loss: 2.2478 - val_accuracy: 0.4856\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1154 - accuracy: 0.5075 - val_loss: 2.2414 - val_accuracy: 0.4856\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.0949 - accuracy: 0.5075 - val_loss: 2.2313 - val_accuracy: 0.4856\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0958 - accuracy: 0.5075 - val_loss: 2.2267 - val_accuracy: 0.4856\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.0964 - accuracy: 0.5075 - val_loss: 2.2272 - val_accuracy: 0.4856\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.0772 - accuracy: 0.5075 - val_loss: 2.2231 - val_accuracy: 0.4856\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.0648 - accuracy: 0.5075 - val_loss: 2.2135 - val_accuracy: 0.4856\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0626 - accuracy: 0.5075 - val_loss: 2.2020 - val_accuracy: 0.4856\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.0382 - accuracy: 0.5075 - val_loss: 2.1938 - val_accuracy: 0.4856\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0525 - accuracy: 0.5075 - val_loss: 2.1934 - val_accuracy: 0.4856\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0333 - accuracy: 0.5075 - val_loss: 2.1911 - val_accuracy: 0.4856\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.0220 - accuracy: 0.5075 - val_loss: 2.1764 - val_accuracy: 0.4856\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0157 - accuracy: 0.5075 - val_loss: 2.1635 - val_accuracy: 0.4856\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.0087 - accuracy: 0.5075 - val_loss: 2.1599 - val_accuracy: 0.4856\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9867 - accuracy: 0.5075 - val_loss: 2.1490 - val_accuracy: 0.4856\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9800 - accuracy: 0.5075 - val_loss: 2.1359 - val_accuracy: 0.4856\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.9742 - accuracy: 0.5075 - val_loss: 2.1309 - val_accuracy: 0.4856\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.9586 - accuracy: 0.5075 - val_loss: 2.1246 - val_accuracy: 0.4856\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9492 - accuracy: 0.5075 - val_loss: 2.1092 - val_accuracy: 0.4856\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.9379 - accuracy: 0.5075 - val_loss: 2.1022 - val_accuracy: 0.4856\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9147 - accuracy: 0.5075 - val_loss: 2.0951 - val_accuracy: 0.4856\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.9107 - accuracy: 0.5075 - val_loss: 2.0810 - val_accuracy: 0.4856\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.8925 - accuracy: 0.5075 - val_loss: 2.0792 - val_accuracy: 0.4856\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.8722 - accuracy: 0.5075 - val_loss: 2.0662 - val_accuracy: 0.4856\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8552 - accuracy: 0.5075 - val_loss: 2.0606 - val_accuracy: 0.4856\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8344 - accuracy: 0.5075 - val_loss: 2.0591 - val_accuracy: 0.4856\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8320 - accuracy: 0.5075 - val_loss: 2.0446 - val_accuracy: 0.4856\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8182 - accuracy: 0.5075 - val_loss: 2.0395 - val_accuracy: 0.4856\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.7994 - accuracy: 0.5075 - val_loss: 2.0314 - val_accuracy: 0.4856\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1.7714 - accuracy: 0.5075 - val_loss: 2.0259 - val_accuracy: 0.4856\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.7628 - accuracy: 0.5089 - val_loss: 2.0228 - val_accuracy: 0.4856\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.7607 - accuracy: 0.5089 - val_loss: 2.0202 - val_accuracy: 0.4856\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.7409 - accuracy: 0.5089 - val_loss: 2.0193 - val_accuracy: 0.4888\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7218 - accuracy: 0.5117 - val_loss: 2.0166 - val_accuracy: 0.4920\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.7197 - accuracy: 0.5254 - val_loss: 2.0176 - val_accuracy: 0.4920\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.7073 - accuracy: 0.5144 - val_loss: 2.0174 - val_accuracy: 0.4920\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6905 - accuracy: 0.5213 - val_loss: 2.0177 - val_accuracy: 0.4952\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.6848 - accuracy: 0.5254 - val_loss: 2.0165 - val_accuracy: 0.5016\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.6618 - accuracy: 0.5295 - val_loss: 2.0200 - val_accuracy: 0.4952\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6696 - accuracy: 0.5254 - val_loss: 2.0267 - val_accuracy: 0.4952\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.6530 - accuracy: 0.5295 - val_loss: 2.0253 - val_accuracy: 0.4920\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6428 - accuracy: 0.5336 - val_loss: 2.0293 - val_accuracy: 0.4920\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6436 - accuracy: 0.5254 - val_loss: 2.0245 - val_accuracy: 0.4920\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.6142 - accuracy: 0.5226 - val_loss: 2.0244 - val_accuracy: 0.4888\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 1.6162 - accuracy: 0.5336 - val_loss: 2.0376 - val_accuracy: 0.4888\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5992 - accuracy: 0.5281 - val_loss: 2.0316 - val_accuracy: 0.4888\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5915 - accuracy: 0.5418 - val_loss: 2.0481 - val_accuracy: 0.4888\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 1.5802 - accuracy: 0.5364 - val_loss: 2.0300 - val_accuracy: 0.4920\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 1.5824 - accuracy: 0.5487 - val_loss: 2.0483 - val_accuracy: 0.4856\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.5642 - accuracy: 0.5473 - val_loss: 2.0411 - val_accuracy: 0.4888\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 1.5634 - accuracy: 0.5624 - val_loss: 2.0390 - val_accuracy: 0.4920\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.5270 - accuracy: 0.5514 - val_loss: 2.0361 - val_accuracy: 0.4984\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.5085 - accuracy: 0.5624 - val_loss: 2.0275 - val_accuracy: 0.5016\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 1.4954 - accuracy: 0.5706 - val_loss: 2.0579 - val_accuracy: 0.4984\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 1.4825 - accuracy: 0.5583 - val_loss: 2.0354 - val_accuracy: 0.5048\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.4708 - accuracy: 0.5802 - val_loss: 2.0364 - val_accuracy: 0.5048\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.4461 - accuracy: 0.5912 - val_loss: 2.0423 - val_accuracy: 0.4984\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.4276 - accuracy: 0.5761 - val_loss: 2.0303 - val_accuracy: 0.5016\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 1.4117 - accuracy: 0.5940 - val_loss: 2.0315 - val_accuracy: 0.5048\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.4071 - accuracy: 0.5995 - val_loss: 2.0014 - val_accuracy: 0.5112\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 1.3725 - accuracy: 0.5953 - val_loss: 2.0156 - val_accuracy: 0.5112\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.3597 - accuracy: 0.6187 - val_loss: 2.0115 - val_accuracy: 0.5144\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.3395 - accuracy: 0.6091 - val_loss: 2.0071 - val_accuracy: 0.5144\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.3335 - accuracy: 0.6049 - val_loss: 2.0008 - val_accuracy: 0.5144\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 1.3040 - accuracy: 0.6145 - val_loss: 2.0199 - val_accuracy: 0.5176\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 1.2471 - accuracy: 0.6392 - val_loss: 2.0361 - val_accuracy: 0.5367\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 143ms/step - loss: 1.2649 - accuracy: 0.6324 - val_loss: 2.0407 - val_accuracy: 0.5272\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 130ms/step - loss: 1.2047 - accuracy: 0.6653 - val_loss: 2.0223 - val_accuracy: 0.5272\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.1822 - accuracy: 0.6584 - val_loss: 2.0798 - val_accuracy: 0.5335\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.1582 - accuracy: 0.6653 - val_loss: 2.0158 - val_accuracy: 0.5240\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.1365 - accuracy: 0.6790 - val_loss: 2.1221 - val_accuracy: 0.5399\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.1234 - accuracy: 0.6667 - val_loss: 2.0630 - val_accuracy: 0.5304\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.1197 - accuracy: 0.6763 - val_loss: 2.1328 - val_accuracy: 0.5463\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.0890 - accuracy: 0.6914 - val_loss: 2.1034 - val_accuracy: 0.5463\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.0951 - accuracy: 0.6735 - val_loss: 2.1254 - val_accuracy: 0.5463\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.0099 - accuracy: 0.6900 - val_loss: 2.1550 - val_accuracy: 0.5431\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.0297 - accuracy: 0.7174 - val_loss: 2.1559 - val_accuracy: 0.5399\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.0087 - accuracy: 0.7010 - val_loss: 2.2332 - val_accuracy: 0.5463\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.9893 - accuracy: 0.7147 - val_loss: 2.1595 - val_accuracy: 0.5304\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.0239 - accuracy: 0.7010 - val_loss: 2.3000 - val_accuracy: 0.5272\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.9347 - accuracy: 0.7243 - val_loss: 2.1995 - val_accuracy: 0.5431\n",
            "Large CNN Error: 45.69%\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "Precision: 0.543\n",
            "Recall: 0.543\n",
            "Accuracy: 0.543\n",
            "F1-Score: 0.543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "g3AjPspDQ0nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c829833f-7269-4274-9f14-821fbcb3fa01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5654952076677316,\n",
              " 0.5686900958466453,\n",
              " 0.5015974440894568,\n",
              " 0.5143769968051118,\n",
              " 0.5143769968051118,\n",
              " 0.48242811501597443,\n",
              " 0.5047923322683706,\n",
              " 0.5559105431309904,\n",
              " 0.5175718849840255,\n",
              " 0.5431309904153354]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}